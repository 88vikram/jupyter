{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark last visit\n",
    "This python notebook trains, tests and evaluates the benchmark last visit. In the first piece of code, testing is done on a longitudinal data set (D2) and in the second piece of code, tesing is done on a cross-sectional data set (D3).\n",
    "Data set used for training and evalution are D1_D2 and D4 ADNI data sets respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model on data set D1_D2 and test model on longitudinal data set D2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from tadpole_algorithms.models import BenchmarkLastVisit\n",
    "from tadpole_algorithms.preprocessing.split import split_test_train_tadpole\n",
    "\n",
    "\"\"\"\n",
    "Train model on ADNI data set D1_D2\n",
    "Test model on ADNI data set D2 rollover participants\n",
    "\"\"\"\n",
    "\n",
    "# Load D1_D2 train and possible test data set\n",
    "data_path_train_test = Path(\"data/TADPOLE_D1_D2.csv\")\n",
    "data_df_train_test = pd.read_csv(data_path_train_test)\n",
    "\n",
    "# Load D4 evaluation data set \n",
    "data_path_eval = Path(\"data/TADPOLE_D4_corr.csv\")\n",
    "data_df_eval = pd.read_csv(data_path_eval)\n",
    "\n",
    "# Split data in test, train and evaluation data\n",
    "train_df, test_df, eval_df = split_test_train_tadpole(data_df_train_test, data_df_eval)\n",
    "test_df = test_df.fillna(0)\n",
    "\n",
    "# Define and train model\n",
    "model = BenchmarkLastVisit()\n",
    "model.train(train_df)\n",
    "\n",
    "# Predict forecast on the test set\n",
    "forecast_df_d2 = model.predict(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model on data set D1_D2 and test model on cross sectional data set D3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from tadpole_algorithms.models import BenchmarkLastVisit\n",
    "from tadpole_algorithms.preprocessing.split import split_test_train_d3\n",
    "from tadpole_algorithms.preprocessing.rewrite_df import rewrite_d3\n",
    "\n",
    "\"\"\"\n",
    "Train model on ADNI data set D1_D2\n",
    "Test model on ADNI data set D3 rollover participants\n",
    "\"\"\"\n",
    "\n",
    "# Load D1_D2 train and possible test data set\n",
    "data_path_train = Path(\"data/TADPOLE_D1_D2.csv\")\n",
    "data_df_train = pd.read_csv(data_path_train)\n",
    "\n",
    "# Load D3 possible test set\n",
    "data_path_test = Path(\"data/TADPOLE_D3.csv\")\n",
    "data_df_test = pd.read_csv(data_path_test)\n",
    "\n",
    "# Load D4 evaluation data set\n",
    "data_path_eval = Path(\"data/TADPOLE_D4_corr.csv\")\n",
    "data_df_eval = pd.read_csv(data_path_eval)\n",
    "\n",
    "# Split data in test, train and evulation data\n",
    "train_df, test_df, eval_df = split_test_train_d3(data_df_train, data_df_test, data_df_eval)\n",
    "test_df = test_df.fillna(0)\n",
    "test_df = rewrite_d3(test_df)\n",
    "\n",
    "# Define and train model\n",
    "model = BenchmarkLastVisit()\n",
    "model.train(train_df)\n",
    "\n",
    "# Predict forecast on the test set\n",
    "forecast_df_d3 = model.predict(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model tested on D2 on ADNI data set D4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[69  8  9]\n [16 61 15]\n [ 2 12 18]]\nmAUC (multiclass Area Under Curve): 0.745\nbca (balanced classification accuracy): 0.763\nadasMAE (ADAS13 Mean Aboslute Error): 6.960\nventsMAE (Ventricles Mean Aboslute Error): 0.012\nadasWES (ADAS13 Weighted Error Score): 7.057\nventsWES (Ventricles Weighted Error Score ): 0.006\nadasCPA (ADAS13 Coverage Probability Accuracy for 50% Confidence Interval: 0.422\nventsCPA (Ventricles Coverage Probability Accuracy for 50% Confidence Interval: 0.013\n"
    }
   ],
   "source": [
    "from tadpole_algorithms.evaluation import evaluate_forecast\n",
    "from tadpole_algorithms.evaluation import print_metrics\n",
    "\n",
    "# Evaluate the model \n",
    "dictionary = evaluate_forecast(eval_df, forecast_df_d2)\n",
    "\n",
    "# Print metrics\n",
    "print_metrics(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model tested on D3 on ADNI data set D4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[69  8  9]\n [16 64 12]\n [ 2 12 18]]\nmAUC (multiclass Area Under Curve): 0.753\nbca (balanced classification accuracy): 0.771\nadasMAE (ADAS13 Mean Aboslute Error): 6.969\nventsMAE (Ventricles Mean Aboslute Error): 0.012\nadasWES (ADAS13 Weighted Error Score): 7.066\nventsWES (Ventricles Weighted Error Score ): 0.006\nadasCPA (ADAS13 Coverage Probability Accuracy for 50% Confidence Interval: 0.422\nventsCPA (Ventricles Coverage Probability Accuracy for 50% Confidence Interval: 0.020\n"
    }
   ],
   "source": [
    "from tadpole_algorithms.evaluation import evaluate_forecast\n",
    "from tadpole_algorithms.evaluation import print_metrics\n",
    "\n",
    "# Evaluate the model \n",
    "dictionary = evaluate_forecast(eval_df, forecast_df_d3)\n",
    "\n",
    "# Print metrics\n",
    "print_metrics(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}