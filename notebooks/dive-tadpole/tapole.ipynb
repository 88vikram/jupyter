{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from socket import gethostname\n",
    "from voxCommon import addParserArgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description = 'Launches clustering model on '\n",
    "                                               'using cortical thickness maps derived from MRI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "addParserArgs(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(agg=0, cluster=False, fwhmLevel=0, informPrior=1, initClustering='hist', lambdaMRF=None, leaderboard=0, modelToRun=None, models=13, nrClust=2, nrInnerIt=None, nrOuterIt=None, nrProc=1, rangeFactor=2, reduceSpace=1, runIndex=1, runPartCogCorr='R', runPartCogCorrMain='RRRRR', runPartMain='RII', runPartStd='RRRRR', stdBeta=0.1, stdGammaAlpha=0.0025)\n"
     ]
    }
   ],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.agg:\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from voxCommon import *\n",
    "import evaluationFramework\n",
    "from voxelDPM import *\n",
    "from aux import *\n",
    "from adniCommon import *\n",
    "from env import *\n",
    "import pandas as pd\n",
    "import PlotterVDPM\n",
    "import VDPMNan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape_alpha 160000.0\n",
      "rate_alpha 160000.0\n",
      "mu_beta 0\n",
      "std_beta 0.1\n"
     ]
    }
   ],
   "source": [
    "params, plotTrajParams = initCommonVoxParams(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrajParams['legendCols'] = 4\n",
    "plotTrajParams['diagColors'] = {CTL:'b', MCI:'g', AD:'r', -1:'y'}\n",
    "plotTrajParams['diagLabels'] = {CTL:'CTL', MCI:'MCI', AD:'AD', -1:'N/A'}\n",
    "plotTrajParams['ylimitsRandPoints'] = (-5,5)\n",
    "plotTrajParams['diagNrs'] = [CTL, MCI, AD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrajParams['SubfigClustMaxWinSize'] = (1300, plotTrajParams['SubfigClustMaxWinSize'][1])\n",
    "plotTrajParams['Clust3DMaxWinSize'] = (900, 600)\n",
    "# plotTrajParams['ylimTrajWeightedDataMean'] = (-3,2)\n",
    "plotTrajParams['ylimTrajSamplesInOneNoData'] = (-2.5,1.5)\n",
    "plotTrajParams['biomkAxisLabel'] = 'Cortical Thickness Z-score'\n",
    "plotTrajParams['biomkWasInversed'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "refDate = datetime.date(2000, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanTadpoleData(df):\n",
    "\n",
    "  df.loc[df.RAVLT_learning < 0, 'RAVLT_learning'] = np.nan\n",
    "  df.loc[df.RAVLT_forgetting < 0, 'RAVLT_forgetting'] = np.nan\n",
    "  df.loc[df.RAVLT_perc_forgetting < 0, 'RAVLT_perc_forgetting'] = np.nan\n",
    "\n",
    "\n",
    "  petCols = list(df.loc[:, 'HIPPL01_BAIPETNMRC_09_12_16' : 'MCSUVRCERE_BAIPETNMRC_09_12_16'])\n",
    "  # df[petCols].replace({'-4': np.nan, -4: np.nan}, inplace=True)\n",
    "  for c in petCols:\n",
    "    df.loc[df[c] == '-4', c] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateDiffToMonths(diff):\n",
    "  return diff.days / (365.0 / 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseTadpoleData(df):\n",
    "\n",
    "  cols = list(df.loc[:, 'FDG':'EcogSPTotal']) + list(df.loc[:, 'Ventricles':'MidTemp']) \\\n",
    "     + list(df.loc[:, 'ST101SV_UCSFFSL_02_01_16_UCSFFSL51ALL_08_01_16':'ST9SV_UCSFFSL_02_01_16_UCSFFSL51ALL_08_01_16']) \\\n",
    "     + list(df.loc[:, 'ST101SV_UCSFFSX_11_02_15_UCSFFSX51_08_01_16':'ST9SV_UCSFFSX_11_02_15_UCSFFSX51_08_01_16']) \\\n",
    "     + list(df.loc[:, 'HIPPL01_BAIPETNMRC_09_12_16':'MCSUVRCERE_BAIPETNMRC_09_12_16']) \\\n",
    "     + list(df.loc[:, 'CEREBELLUMGREYMATTER_UCBERKELEYAV45_10_17_16':'WM_HYPOINTENSITIES_SIZE_UCBERKELEYAV45_10_17_16']) \\\n",
    "     + list(df.loc[:, 'CEREBELLUMGREYMATTER_UCBERKELEYAV1451_10_17_16':'WM_HYPOINTENSITIES_SIZE_UCBERKELEYAV1451_10_17_16']) \\\n",
    "     + list(df.loc[:, 'FA_CST_L_DTIROI_04_30_14':'AD_SUMFX_DTIROI_04_30_14']) \\\n",
    "     + list(df.loc[:, 'ABETA_UPENNBIOMK9_04_19_17':'PTAU_UPENNBIOMK9_04_19_17'])\n",
    "\n",
    "\n",
    "  # TODO: re-process data more, continue form here: change AV45 -> AV45/SIZE of ROI\n",
    "  #print('cols', cols)\n",
    "  # filter out the FS cols with Standard deviation of volumes, cort thickness, etc ... Only keep average\n",
    "  colsFilt = []\n",
    "  for col in cols:\n",
    "    if col[:2] == 'ST' and (col[5] == 'S' or col[6] == 'S'):\n",
    "      continue\n",
    "\n",
    "    colsFilt += [col]\n",
    "\n",
    "\n",
    "  # print(ads)\n",
    "  # print(df.D1)\n",
    "  # print(df.shape)\n",
    "  d2Ind = df.RID[df.loc[:,'D2'] == 1].values\n",
    "\n",
    "  print('d2Ind', np.unique(d2Ind), np.unique(d2Ind).shape)\n",
    "\n",
    "\n",
    "  df[cols] = df[cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "  pickle.dump(dict(df=df), open('tadpoleCleanDf.npz', 'wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "  df = pickle.load(open('tadpoleCleanDf.npz', 'rb'))['df']\n",
    "\n",
    "\n",
    "  # normalise ventricles by ICV\n",
    "  df['Ventricles'] = df['Ventricles'] / df['ICV']\n",
    "\n",
    "\n",
    "  data = df.values(columns=cols)\n",
    "\n",
    "\n",
    "  # convert diagnoses such as 'MCI to Dementia' to 'Dementia', etc ...\n",
    "  # ctlDxchange = [1, 7, 9] mciDxchange = [2, 4, 8] adDxChange = [3, 5, 6]\n",
    "  mapping = {1: CTL, 7: CTL, 9: CTL, 2: MCI, 4: MCI, 8: MCI, 3: AD, 5: AD, 6: AD}\n",
    "  # df.replace({'DXCHANGE': mapping}, inplace=True)\n",
    "  df['DXCHANGE'] = df['DXCHANGE'].map(mapping)\n",
    "  diag = df['DXCHANGE'].values()\n",
    "\n",
    "  examDates = df.EXAMDATE.values()\n",
    "  df['EXAMDATE'] = pd.to_datetime(df['EXAMDATE'], format=\"%Y-%m-%d\")\n",
    "\n",
    "  dataDf = df[cols]\n",
    "  dataDf.to_csv('tadpoleCleanDf.csv')\n",
    "\n",
    "  # build numpy string array\n",
    "  nrCols = len(cols)\n",
    "  labels = np.ndarray((nrCols,), dtype='S100')\n",
    "  for c in range(nrCols):\n",
    "    labels[c] = cols[c]\n",
    "\n",
    "  partCode = df.RID.values()\n",
    "\n",
    "  unqPartCode = np.unique(partCode)\n",
    "  nrUnqSubj = len(unqPartCode)\n",
    "\n",
    "  ageAtScan = np.zeros(partCode.shape, np.float)\n",
    "  scanTimepts = np.zeros(partCode.shape, np.float)\n",
    "\n",
    "  for s in range(nrUnqSubj):\n",
    "    subjRowsCurr = df.RID == unqPartCode[s]\n",
    "    ageAtBlCurr = df.AGE[subjRowsCurr]\n",
    "    examDatesCurr = df.EXAMDATE[subjRowsCurr]\n",
    "\n",
    "    minInd = np.argmin(examDatesCurr)\n",
    "    yearsDiffs = [(d - examDatesCurr[minInd]).days/365 for d in examDatesCurr]\n",
    "\n",
    "    ageAtScan[subjRowsCurr] = ageAtBlCurr + yearsDiffs\n",
    "\n",
    "    scanTimepts[subjRowsCurr] = np.argsort(np.argsort(yearsDiffs))\n",
    "\n",
    "    sortedVisitsCurr = np.argsort(yearsDiffs)\n",
    "    diagCurrSorted = diag[subjRowsCurr][sortedVisitsCurr]\n",
    "\n",
    "    notNanDiags = [d for d in diagCurrSorted if not np.isnan(d)]\n",
    "\n",
    "    diagCurrSortedFilled = np.copy(diagCurrSorted)\n",
    "\n",
    "    if len(notNanDiags) == 0:\n",
    "      # set the subject diag as -1 if there is absolutely no diagnosis\n",
    "      diagCurrSortedFilled[0] = -1\n",
    "    else:\n",
    "      if np.isnan(diagCurrSortedFilled[0]):\n",
    "        diagCurrSortedFilled[0] = notNanDiags[0]\n",
    "\n",
    "      for v in range(1, len(sortedVisitsCurr)):\n",
    "        if np.isnan(diagCurrSortedFilled[v]):\n",
    "          diagCurrSortedFilled[v] = diagCurrSortedFilled[v-1]\n",
    "\n",
    "\n",
    "    diagFilledInOrigOrder = diagCurrSortedFilled[np.argsort(sortedVisitsCurr)]\n",
    "\n",
    "    diag[subjRowsCurr] = diagFilledInOrigOrder\n",
    "\n",
    "  # compute number of months since Jan 2000 for each EXAMDATEs\n",
    "  monthsSinceRefTime = np.zeros(partCode.shape, np.float)\n",
    "\n",
    "  for r in range(df.RID.shape[0]):\n",
    "    monthsSinceRefTime[r] = dateDiffToMonths(df.EXAMDATE[r].date() - refDate)\n",
    "\n",
    "\n",
    "  assert not np.isnan(ageAtScan).any()\n",
    "  assert not np.isnan(diag).any()\n",
    "  assert not np.isnan(scanTimepts).any()\n",
    "  assert not np.isnan(partCode).any()\n",
    "  assert not np.isnan(monthsSinceRefTime).any()\n",
    "\n",
    "  return data, diag, labels, scanTimepts, partCode, ageAtScan, dataDf, \\\n",
    "    monthsSinceRefTime, examDates, d2Ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeBiomksDecr(data, diag, labels):\n",
    "\n",
    "  assert(data.shape[0] == diag.shape[0])\n",
    "\n",
    "  # perform t-test on every voxel, sort them by p-values\n",
    "  pVals = scipy.stats.ttest_ind(data[diag == CTL,:], data[diag == AD,:], nan_policy='omit')[1]\n",
    "\n",
    "  sortedInd = np.argsort(pVals)\n",
    "  print('sortedInd', sortedInd)\n",
    "\n",
    "  print('data[diag == CTL, :]', data[diag == CTL, :])\n",
    "  meanCTL = np.nanmean(data[diag == CTL, :], axis=0)\n",
    "  meanAD =  np.nanmean(data[diag == AD, :], axis=0)\n",
    "  stdCTL = np.nanstd(data[diag == CTL, :], axis=0)\n",
    "  stdAD = np.nanstd(data[diag == AD, :], axis=0)\n",
    "\n",
    "  # record which biomarkers have had their sign flipped. Multiply this vector\n",
    "  # with the scale from the normalisation with controls that we did earlier.\n",
    "  biomkScaleExtra = np.ones(pVals.shape)\n",
    "\n",
    "  for b in sortedInd:\n",
    "\n",
    "    if (pVals[b] < 0.001) and meanAD[b] > meanCTL[b]:\n",
    "      data[:,b] = data[:,b] * (-1)\n",
    "      biomkScaleExtra[b] = -1\n",
    "      #print('flipped sign for %s' % labels[b])\n",
    "\n",
    "  return data, sortedInd, biomkScaleExtra, pVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visTadpoleHist(data, diag, age, labels, plotTrajParams, sortedByPvalInd):\n",
    "  '''\n",
    "  Plots average biomarker value for various ROIs\n",
    "\n",
    "  :param data: NR_CROSS_SUBJ x NR_BIOMK array\n",
    "  :param diag: NR_CROSS_SUBJ x 1\n",
    "  :param age:  NR_CROSS_SUBJ x 1\n",
    "  :param plotTrajParams: dictionary of plotting parameters\n",
    "  :param sortedByPvalInd: ROI indicesof each point on the surface, sorted by p-value (the regions for which we observe the highest differences between CTL and AD apprear first)\n",
    "\n",
    "  :return: figure handle\n",
    "  '''\n",
    "\n",
    "\n",
    "  fig = pl.figure()\n",
    "  nrRows = 3\n",
    "  nrCols = 4\n",
    "  nrBiomkToDisplay = nrRows * nrCols\n",
    "\n",
    "  nrSubj, nrBiomk = data.shape\n",
    "\n",
    "  xs = np.linspace(np.min(age), np.max(age), 100)\n",
    "  diagNrs = plotTrajParams['diagNrs']\n",
    "\n",
    "\n",
    "  VDPMNaN.makeLongArray(data, scanTimepts, partCode, np.unique(partCode))\n",
    "\n",
    "  for row in range(nrRows):\n",
    "    for col in range(nrCols):\n",
    "      b = row * nrCols + col # clusterNr\n",
    "      print('Plotting biomk:', b)\n",
    "\n",
    "      if b < nrBiomk:\n",
    "        ax = pl.subplot(nrRows, nrCols, 1+np.mod(b, nrBiomkToDisplay))\n",
    "        ax.set_title('b%d %s' % (b, labels[b][:10]))\n",
    "\n",
    "        nnMask = np.logical_not(np.isnan(data[:,b]))\n",
    "        dataNotNanS = data[nnMask,b]\n",
    "        diagNotNanS = diag[nnMask]\n",
    "        ageNotNanS = age[nnMask]\n",
    "\n",
    "        print('dataNotNanS', dataNotNanS)\n",
    "        print('\\ndiagNotNanS', diagNotNanS)\n",
    "\n",
    "        for d in range(len(diagNrs)):\n",
    "          ax.hist(dataNotNanS[diagNotNanS == diagNrs[d]],bins=20, alpha=0.5,\n",
    "            label=plotTrajParams['diagLabels'][diagNrs[d]], color=plotTrajParams['diagColors'][diagNrs[d]])\n",
    "\n",
    "        if col == 0:\n",
    "          ax.set_ylabel('Z-score')\n",
    "\n",
    "        if row == (nrRows - 1):\n",
    "          ax.set_xlabel('biomk value')\n",
    "        else:\n",
    "          ax.set_xticks([])\n",
    "\n",
    "        if b == 0:\n",
    "          adjustCurrFig(plotTrajParams)\n",
    "          fig.suptitle('indiv points', fontsize=20)\n",
    "\n",
    "          h, axisLabels = ax.get_legend_handles_labels()\n",
    "\n",
    "          legend = pl.figlegend(h, axisLabels, loc='lower center', ncol=plotTrajParams['legendCols'], labelspacing=0. )\n",
    "\n",
    "          mng = pl.get_current_fig_manager()\n",
    "          mng.resize(*plotTrajParams['SubfigVisMaxWinSize'])\n",
    "\n",
    "  pl.show()\n",
    "\n",
    "  return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visTadpoleSpagetti(data, diag, age, scanTimepts, partCode, labels, plotTrajParams, sortedByPvalInd):\n",
    "  '''\n",
    "  Plots average biomarker value for various ROIs\n",
    "\n",
    "  :param data: NR_CROSS_SUBJ x NR_BIOMK array\n",
    "  :param diag: NR_CROSS_SUBJ x 1\n",
    "  :param age:  NR_CROSS_SUBJ x 1\n",
    "  :param plotTrajParams: dictionary of plotting parameters\n",
    "  :param sortedByPvalInd: ROI indicesof each point on the surface, sorted by p-value (the regions for which we observe the highest differences between CTL and AD apprear first)\n",
    "\n",
    "  :return: figure handle\n",
    "  '''\n",
    "\n",
    "\n",
    "  fig = pl.figure()\n",
    "  nrRows = 3\n",
    "  nrCols = 4\n",
    "  nrBiomkToDisplay = nrRows * nrCols\n",
    "\n",
    "  nrSubj, nrBiomk = data.shape\n",
    "\n",
    "  xs = np.linspace(np.min(age), np.max(age), 100)\n",
    "  diagNrs = plotTrajParams['diagNrs']\n",
    "  # import VDPMNan\n",
    "  unqPartCode = np.unique(partCode)\n",
    "  longData = VDPMNan.VDPMNan.makeLongArray(None, data, scanTimepts, partCode, unqPartCode)\n",
    "  longDiag = VDPMNan.VDPMNan.makeLongArray(None, diag, scanTimepts, partCode, unqPartCode)\n",
    "  longAge = VDPMNan.VDPMNan.makeLongArray(None, age, scanTimepts, partCode, unqPartCode)\n",
    "  nrLongSubj = len(longDiag)\n",
    "\n",
    "  for row in range(nrRows):\n",
    "    for col in range(nrCols):\n",
    "      b = row * nrCols + col # clusterNr\n",
    "      print('Plotting biomk:', b)\n",
    "\n",
    "      if b < nrBiomk:\n",
    "        ax = pl.subplot(nrRows, nrCols, 1+np.mod(b, nrBiomkToDisplay))\n",
    "        ax.set_title('b%d %s' % (b, labels[b][:10]))\n",
    "\n",
    "        nnMask = np.logical_not(np.isnan(data[:,b]))\n",
    "        dataNotNanS = data[nnMask,b]\n",
    "        diagNotNanS = diag[nnMask]\n",
    "        ageNotNanS = age[nnMask]\n",
    "\n",
    "        # print('dataNotNanS', dataNotNanS)\n",
    "        # print('diagNotNanS', diagNotNanS)\n",
    "\n",
    "        for s in range(nrLongSubj):\n",
    "          # print('longAge[s]', longAge[s])\n",
    "          # print('longData[s][:,b]', longData[s][:,b])\n",
    "          # print('longDiag[s][0]', longDiag[s][0])\n",
    "          pl.plot(longAge[s], longData[s][:,b], c=plotTrajParams['diagColors'][longDiag[s][0]],\n",
    "            label=plotTrajParams['diagLabels'][longDiag[s][0]])\n",
    "\n",
    "        if col == 0:\n",
    "          ax.set_ylabel('biomarker')\n",
    "\n",
    "        if row == (nrRows - 1):\n",
    "          ax.set_xlabel('age')\n",
    "        else:\n",
    "          ax.set_xticks([])\n",
    "\n",
    "        if b == 0:\n",
    "          adjustCurrFig(plotTrajParams)\n",
    "          fig.suptitle('indiv points', fontsize=20)\n",
    "\n",
    "          h, axisLabels = ax.get_legend_handles_labels()\n",
    "\n",
    "          legend = pl.figlegend(h, axisLabels, loc='lower center', ncol=plotTrajParams['legendCols'], labelspacing=0. )\n",
    "\n",
    "          mng = pl.get_current_fig_manager()\n",
    "          mng.resize(*plotTrajParams['SubfigVisMaxWinSize'])\n",
    "\n",
    "  pl.show()\n",
    "\n",
    "  return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launchTadpole(runIndex, nrProcesses, modelToRun):\n",
    "\n",
    "  genProcessedDataset = 1\n",
    "\n",
    "  if genProcessedDataset:\n",
    "    if args.leaderboard == 0:\n",
    "      inputFileData = 'data/TADPOLE_D1_D2.csv'\n",
    "      sys.stdout.flush()\n",
    "      outFileCheckpoint2 = 'tadpoleDf2.npz'\n",
    "      print('loading data file')\n",
    "      df = pd.read_csv(inputFileData,low_memory=False)\n",
    "      df = cleanTadpoleData(df)\n",
    "      data, diag, labels, scanTimepts, partCode, ageAtScan, dataDf, monthsSinceRefTime, \\\n",
    "        examDates, predInd = parseTadpoleData(df)\n",
    "\n",
    "    else:\n",
    "      outFileCheckpoint2 = 'tadpoleDf2Ldb.npz'\n",
    "      print('loading data file')\n",
    "      inputFileDataD1D2 = 'data/TADPOLE_D1_D2.csv'\n",
    "      df = pd.read_csv(inputFileDataD1D2,low_memory=False)\n",
    "      df = cleanTadpoleData(df)\n",
    "      inputFileDataLB = 'data/TADPOLE_LB1_LB2.csv'\n",
    "      dfLB = pd.read_csv(inputFileDataLB, low_memory=False)\n",
    "\n",
    "      # this function runs exactly as in the normal submission, no difference here for leaderboard\n",
    "      data, diag, labels, scanTimepts, partCode, ageAtScan, dataDf, monthsSinceRefTime, \\\n",
    "        examDates, _ = parseTadpoleData(df)\n",
    "\n",
    "      filterMaskLB12 = np.logical_or(dfLB.LB1 == 1, dfLB.LB2 == 1)\n",
    "      assert data.shape[0] == dfLB.shape[0]\n",
    "\n",
    "      # print(np.sum(filterMaskLB12), filterMaskLB12.shape[0])\n",
    "      # print(dads)\n",
    "\n",
    "      data = data[filterMaskLB12,:]\n",
    "      diag = diag[filterMaskLB12]\n",
    "      scanTimepts = scanTimepts[filterMaskLB12]\n",
    "      partCode = partCode[filterMaskLB12]\n",
    "      ageAtScan = ageAtScan[filterMaskLB12]\n",
    "      dataDf = dataDf[filterMaskLB12]\n",
    "      dataDf.reset_index(drop=True, inplace=True)\n",
    "      dataDf.reindex(index=range(dataDf.shape[0]))\n",
    "      monthsSinceRefTime = monthsSinceRefTime[filterMaskLB12]\n",
    "      examDates = examDates[filterMaskLB12]\n",
    "      predInd = dfLB.RID[dfLB.LB2 == 1].values()\n",
    "\n",
    "    dataStruct = dict(data=data, diag=diag, labels=labels, scanTimepts=scanTimepts,\n",
    "      partCode=partCode, ageAtScan=ageAtScan, dataDf=dataDf,\n",
    "      monthsSinceRefTime=monthsSinceRefTime, examDates=examDates, predInd=predInd)\n",
    "    pickle.dump(dataStruct, open(outFileCheckpoint2, 'wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "  else:\n",
    "    if args.leaderboard == 0:\n",
    "      outFileCheckpoint2 = 'tadpoleDf2.npz'\n",
    "    else:\n",
    "      outFileCheckpoint2 = 'tadpoleDf2Ldb.npz'\n",
    "\n",
    "\n",
    "  dataStruct = pickle.load(open(outFileCheckpoint2, 'rb'))\n",
    "  data = dataStruct['data']\n",
    "  diag = dataStruct['diag']\n",
    "  labels = dataStruct['labels']\n",
    "  scanTimepts = dataStruct['scanTimepts']\n",
    "  partCode = dataStruct['partCode']\n",
    "  ageAtScan = dataStruct['ageAtScan']\n",
    "  # dataDf = dataStruct['dataDf']\n",
    "  monthsSinceRefTime = dataStruct['monthsSinceRefTime']\n",
    "  examDates = dataStruct['examDates']\n",
    "  predInd = dataStruct['predInd']\n",
    "\n",
    "\n",
    "  # filter AD subjects\n",
    "  # diagInd = np.array(np.where(matData['diag'] == PCA)[0])\n",
    "  print('compiling parameters')\n",
    "  sys.stdout.flush()\n",
    "\n",
    "  print('diag', np.unique(diag), diag)\n",
    "  # print(adsas)\n",
    "\n",
    "  unqPartCode = np.unique(partCode)\n",
    "  nrUnqPart = len(unqPartCode)\n",
    "\n",
    "  # calculate Z-scores at each point w.r.t controls at baseline\n",
    "  # controlBlInd = np.logical_and(diag == CTL, scanTimepts == 1)\n",
    "  controlInd = diag == CTL\n",
    "  stdBiomk = np.nanstd(data[diag == CTL], 0)\n",
    "  biomkMaskCTL = np.isnan(np.nanstd(data[diag == CTL], 0))\n",
    "  biomkMaskAD = np.isnan(np.nanstd(data[diag == AD], 0))\n",
    "  biomkMaskMCI = np.isnan(np.nanstd(data[diag == MCI], 0))\n",
    "  mask = np.logical_or(np.logical_or(biomkMaskCTL, biomkMaskMCI), biomkMaskAD)\n",
    "  # print(ads)\n",
    "  selectedBiomk = np.logical_not(np.logical_or(mask, stdBiomk == 0))\n",
    "\n",
    "  print(data.shape)\n",
    "  data = data[:, selectedBiomk]\n",
    "  labels = labels[selectedBiomk]\n",
    "  pointIndices = np.array(range(data.shape[1]))\n",
    "  stdBiomk = np.nanstd(data[controlInd], 0)\n",
    "  print(data.shape)\n",
    "  # print(ads)\n",
    "\n",
    "  meanCTL = np.nanmean(data[controlInd], 0)  # calculate Z-scores\n",
    "  stdCTL = np.nanstd(data[controlInd], 0)\n",
    "  dataZ = (data - meanCTL[None,:])/stdCTL[None,:]\n",
    "  data = dataZ\n",
    "\n",
    "  outlierRows, outlierCols = np.where(np.abs(dataZ) > 50)\n",
    "  filterMask = np.ones(data.shape[0], bool)\n",
    "  filterMask[outlierRows] = 0\n",
    "  data = data[filterMask]\n",
    "  diag = diag[filterMask]\n",
    "  scanTimepts = scanTimepts[filterMask]\n",
    "  partCode = partCode[filterMask]\n",
    "  ageAtScan = ageAtScan[filterMask]\n",
    "  monthsSinceRefTime = monthsSinceRefTime[filterMask]\n",
    "  examDates = examDates[filterMask]\n",
    "  meanAgeAtScan = np.mean(ageAtScan.astype(float))\n",
    "  ageAtScanCentered = (ageAtScan - meanAgeAtScan).astype(np.float16)\n",
    "\n",
    "  nrSubj, nrBiomk = data.shape\n",
    "  # print('nrBiomk', nrBiomk)\n",
    "  # print(adsa)\n",
    "\n",
    "  dataAD = data[diag == AD, :]\n",
    "\n",
    "  # make all biomarkers decreasing by flipping their signs if necessary\n",
    "  # also perform a t-test to see which ones are most informative, sort them by pvalue (i.e. sortedByPvalInd)\n",
    "  # the new data is re-scaled\n",
    "  data, sortedByPvalInd, biomkScaleExtra, pVals = makeBiomksDecr(data, diag, labels)\n",
    "  #doTtest(data, diag, pointIndices)\n",
    "\n",
    "  # multiply the scaling we did from controls with (-1) if the biomk had the sign flipped\n",
    "  stdBiomkRescale = biomkScaleExtra * stdCTL\n",
    "\n",
    "  assert(sortedByPvalInd.shape[0] == data.shape[1])\n",
    "\n",
    "  sys.stdout.flush()\n",
    "\n",
    "  global params\n",
    "\n",
    "  params['data'] = data\n",
    "  params['diag'] = diag\n",
    "  params['scanTimepts'] = scanTimepts\n",
    "  params['partCode'] = partCode\n",
    "  params['ageAtScan'] = ageAtScan\n",
    "  params['initShift'] = ageAtScanCentered # initialise time shifts (betas) to (age - meanAge)\n",
    "  params['biomkDir'] = DECR\n",
    "  params['modelToRun'] = modelToRun\n",
    "  params['datasetFull'] = 'tadpole'\n",
    "  params['labels'] = labels\n",
    "  params['predInd'] = predInd\n",
    "  params['examDates'] = examDates\n",
    "\n",
    "  # print('ageAtScanCentered', ageAtScanCentered)\n",
    "  # print('ageAtScan', ageAtScan)\n",
    "  # print('scanTimepts', scanTimepts)\n",
    "  # ada\n",
    "\n",
    "  print('outFileCheckpoint2', outFileCheckpoint2)\n",
    "  print('d2Ind', np.unique(predInd), np.unique(predInd).shape)\n",
    "  # print(adsa)\n",
    "\n",
    "  # filter down to 100 subjects to make it run faster, just for testing. Also select only some biomarkers\n",
    "  unqPartCode = np.unique(params['partCode'])\n",
    "  nrPartToSample = 30\n",
    "  np.random.seed(3)\n",
    "  selectedPartCode = np.random.choice(unqPartCode, nrPartToSample)\n",
    "  dataIndices = np.in1d(params['partCode'], selectedPartCode)\n",
    "  # params = filterDDSPAIndices(params, dataIndices)\n",
    "\n",
    "\n",
    "  indices = [i for i in range(len(labels)) if labels[i] in\n",
    "      [b'FDG', b'AV45', b'CDRSB', b'ADAS13', b'Ventricles',\n",
    "       b'Hippocampus', b'WholeBrain', b'Entorhinal', b'MidTemp', b'ABETA_UPENNBIOMK9_04_19_17',\n",
    "       b'TAU_UPENNBIOMK9_04_19_17', b'PTAU_UPENNBIOMK9_04_19_17']]\n",
    "\n",
    "  # indices = sortedByPvalInd[:300]\n",
    "  # print('pVals lowest', pVals[sortedByPvalInd[:300]])\n",
    "  # print('pVals highest', pVals[sortedByPvalInd[-100:]])\n",
    "  # print('indices', indices)\n",
    "  # print(ads)\n",
    "  print('labels', labels[indices])\n",
    "  # print(adsa)\n",
    "  print(np.nanstd(data,axis=0)[indices])\n",
    "  data = params['data'][:,indices]\n",
    "  params['data'] = data\n",
    "  labels = labels[indices]\n",
    "  params['labels'] = labels\n",
    "  nrBiomk = params['data'].shape[1]\n",
    "  print('data.shape', params['data'].shape)\n",
    "  meanCTL = meanCTL[indices]\n",
    "  stdBiomkRescale = stdBiomkRescale[indices]\n",
    "  print(stdBiomkRescale)\n",
    "  print('flippedBiomk', labels[stdBiomkRescale < 0])\n",
    "  sortedByPvalInd = np.argsort(np.argsort(sortedByPvalInd[indices]))\n",
    "\n",
    "  # visTadpoleHist(data, diag, ageAtScan, labels, plotTrajParams, sortedByPvalInd)\n",
    "  # print(adsa)\n",
    "\n",
    "  # visTadpoleSpagetti(data, diag, ageAtScan, scanTimepts, partCode, labels, plotTrajParams, sortedByPvalInd)\n",
    "  # print(adsa)\n",
    "\n",
    "  # print('CTL %f +/- %f', np.nanmean(params['data'][params['diag'] == CTL, 1]), np.nanstd(params['data'][params['diag'] == CTL, 1]))\n",
    "  # print('AD %f +/- %f', np.nanmean(params['data'][params['diag'] == AD, 1]), np.nanstd(params['data'][params['diag'] == AD, 1]))\n",
    "  # print(ads)\n",
    "\n",
    "  plotTrajParams['nearestNeighbours'] = np.array(range(nrBiomk))\n",
    "  params['adjList'] = np.nan\n",
    "  params['nearNeighInitClust'] = np.array(range(nrBiomk))\n",
    "  params['initClustSubsetInd'] = np.array(range(nrBiomk))\n",
    "  params['meanBiomkRescale'] = meanCTL # for rescaling back if necessary\n",
    "  params['stdBiomkRescale'] = stdBiomkRescale\n",
    "  # params['fixSpeed'] = True # if true then don't model progression speed, only time shift\n",
    "  params['fixSpeed'] = False  # if true then don't model progression speed, only time shift\n",
    "\n",
    "  diagNrs = np.unique(diag)\n",
    "  # print('diagNrs, diag', diagNrs, diag)\n",
    "  # print(asdas)\n",
    "\n",
    "  # print(len(params['acqDate']), data.shape[0])\n",
    "  sys.stdout.flush()\n",
    "  assert(params['data'].shape[0] == params['diag'].shape[0] ==\n",
    "    params['scanTimepts'].shape[0] == params['partCode'].shape[0] ==\n",
    "    params['ageAtScan'].shape[0])\n",
    "\n",
    "  # sets an uninformative or informative prior\n",
    "  priorNr = setPrior(params, args.informPrior, mean_gamma_alpha=1,\n",
    "    std_gamma_alpha=0.1, mu_beta=0, std_beta=5)\n",
    "\n",
    "  suffix = ''\n",
    "  if args.leaderboard:\n",
    "    suffix = 'Ldb'\n",
    "    # print(ads)\n",
    "\n",
    "  expName = 'tadpoleInit%sCl%dPr%dRa%d%s' % (args.initClustering, params['nrClust'],\n",
    "    priorNr, args.rangeFactor, suffix)\n",
    "  plotTrajParams['sortedByPvalInd'] = sortedByPvalInd\n",
    "  plotTrajParams['pointIndices'] = pointIndices\n",
    "  plotTrajParams['expName'] = expName\n",
    "  plotTrajParams['ageTransform'] = (0, 1) # no age normalisation was necessary\n",
    "  plotTrajParams['datasetFull'] = params['datasetFull']\n",
    "  plotTrajParams['labels'] = labels\n",
    "\n",
    "  params['plotTrajParams'] = plotTrajParams\n",
    "\n",
    "  # R - run that checkpoint, L - load result from checkpoint\n",
    "  # [initClust, modelFit, AIC/BIC, blender, theta_sampling]\n",
    "  params['runPartStd'] = ['R', 'R', 'I', 'I', 'I']\n",
    "  params['runPartMain'] = ['R', 'I', 'I', 'I']  # [mainPart, plot, stage, globalMinStats]\n",
    "  params['runPartCogCorr'] = ['I']\n",
    "  params['runPartCogCorrMain'] = ['L', 'L', 'I', 'I', 'L']\n",
    "  params['runPartDirDiag'] = ['R', 'R', 'I']\n",
    "  params['runPartStaging'] = ['L', 'L', 'I']\n",
    "  params['runPartDiffDiag'] = ['R', 'R', 'I']\n",
    "  params['runPartConvPred'] = ['I', 'I', 'I']\n",
    "  params['runPartCVNonOverlap'] = ['R']\n",
    "  params['runPartCVNonOverlapMain'] = ['L', 'L', 'I', 'I', 'L']\n",
    "  params['masterProcess'] = runIndex == 0\n",
    "\n",
    "  if params['masterProcess']:\n",
    "    # [initClust, modelFit, AIC/BIC, blender, theta_sampling]\n",
    "    params['runPartStd'] = ['L', 'L', 'I', 'I', 'I']\n",
    "    params['runPartMain'] = ['R', 'R', 'R', 'I']  # [mainPart, plot, stage, globalMinStats]\n",
    "    params['runPartCogCorr'] = ['I']\n",
    "    params['runPartCogCorrMain'] = ['L', 'L', 'I', 'I', 'I']\n",
    "    params['runPartDirDiag'] = ['R', 'R', 'I']\n",
    "    params['runPartStaging'] = ['L', 'L', 'I']\n",
    "    params['runPartDiffDiag'] = ['R', 'R', 'I']\n",
    "    params['runPartConvPred'] = ['I', 'I', 'I']\n",
    "    params['runPartCVNonOverlap'] = ['I']\n",
    "    params['runPartCVNonOverlapMain'] = ['R', 'R', 'I', 'R', 'R']\n",
    "\n",
    "  runAllExpFunc = runAllExpTADPOLE\n",
    "  modelNames, res = evaluationFramework.runModels(params, expName, modelToRun, runAllExpFunc)\n",
    "\n",
    "  # now generate forecast\n",
    "  #print('Generating forecast ... ')\n",
    "  teamName = 'DIVE6'\n",
    "  if args.leaderboard:\n",
    "    outputFile = 'TADPOLE_Submission_Leaderboard_%s.csv' % teamName\n",
    "    predStartDate = datetime.date(2010, 5, 1)\n",
    "    nrYearsToPred = 7\n",
    "    nrMonthsToPred = 12*nrYearsToPred  # 5 years\n",
    "  else:\n",
    "    outputFile = 'TADPOLE_Submission_%s.csv' % teamName\n",
    "    predStartDate = datetime.date(2018, 1, 1)\n",
    "    nrYearsToPred = 5\n",
    "    nrMonthsToPred = 12*nrYearsToPred  # 7 years\n",
    "\n",
    "  resCurrModel = res[0]['std']\n",
    "\n",
    "  predAdasAllSubj, predVentsAllSubj, predDiagAllSubj = makeTadpoleForecast(predStartDate,\n",
    "    nrYearsToPred, nrMonthsToPred, resCurrModel, params)\n",
    "\n",
    "  # write forecast to file\n",
    "  writeTadpoleSubmission(predAdasAllSubj, predVentsAllSubj, predDiagAllSubj, outputFile,\n",
    "    nrMonthsToPred, predStartDate, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTadpoleForecast(predStartDate, nrYearsToPred, nrMonthsToPred, resCurrModel, params):\n",
    "\n",
    "  yearsFromPredStartToEachPredDate = np.linspace(0, nrYearsToPred, num=nrMonthsToPred, endpoint=False)\n",
    "\n",
    "  nrClust = params['nrClust']\n",
    "  assert abs(yearsFromPredStartToEachPredDate[1] - (1.0/12)) < 0.00001\n",
    "  # make predictions\n",
    "  startMonth = dateDiffToMonths(refDate - predStartDate)\n",
    "\n",
    "  trajFunc = sigmoidFunc\n",
    "\n",
    "  unqPartCodeFromRes = resCurrModel['uniquePartCode']\n",
    "  predInd = params['predInd']\n",
    "  predSetRidUnq = np.unique(predInd)\n",
    "\n",
    "  nrSubjPredSet = predSetRidUnq.shape[0]\n",
    "  # for each patient\n",
    "  clustProbBC = resCurrModel['clustProb']\n",
    "  thetas = resCurrModel['thetas']\n",
    "  variances = resCurrModel['variances']\n",
    "\n",
    "  labels = params['labels']\n",
    "  indexAdas = np.where(labels == b'ADAS13')[0][0]\n",
    "  indexVents = np.where(labels == b'Ventricles')[0][0]\n",
    "\n",
    "  predDiagAllSubj = np.zeros((nrSubjPredSet, nrMonthsToPred, 3), np.float)\n",
    "  predAdasAllSubj = np.zeros((nrSubjPredSet, nrMonthsToPred, 3), np.float)\n",
    "  predVentsAllSubj = np.zeros((nrSubjPredSet, nrMonthsToPred, 3), np.float)\n",
    "\n",
    "  dpsCross = resCurrModel['dpsCross']\n",
    "  crossDiag = resCurrModel['crossDiag']\n",
    "\n",
    "  dpsCTL = dpsCross[crossDiag == CTL]\n",
    "  dpsMCI = dpsCross[crossDiag == MCI]\n",
    "  dpsAD = dpsCross[crossDiag == AD]\n",
    "\n",
    "  partCode = params['partCode']\n",
    "  partCodeCurr = resCurrModel['crossPartCode']\n",
    "  # ageAtScan = resCurrModel['ageAtScan']\n",
    "\n",
    "  data = params['data']\n",
    "\n",
    "\n",
    " # print(partCode.shape)\n",
    " #print(partCodeCurr.shape)\n",
    "  assert partCodeCurr.shape[0] == partCode.shape[0]\n",
    "\n",
    "  kernelWidth = np.std(dpsCross)/6 # need to test this parameter by visualisation\n",
    "\n",
    "  from sklearn.neighbors.kde import KernelDensity\n",
    "  kdeCTL = KernelDensity(kernel = 'gaussian', bandwidth = kernelWidth).fit(dpsCTL.reshape(-1,1))\n",
    "  kdeMCI = KernelDensity(kernel = 'gaussian', bandwidth = kernelWidth).fit(dpsMCI.reshape(-1,1))\n",
    "  kdeAD = KernelDensity(kernel = 'gaussian', bandwidth = kernelWidth).fit(dpsAD.reshape(-1,1))\n",
    "\n",
    "  kdeXs = np.linspace(np.min(dpsCross), np.max(dpsCross), num=100).reshape(-1,1)\n",
    "\n",
    "  fig = pl.figure(3)\n",
    "  pl.clf()\n",
    "  #print('kdeCTL.score_samples(kdeXs)', np.exp(kdeCTL.score_samples(kdeXs)))\n",
    "  pl.plot(kdeXs, np.exp(kdeCTL.score_samples(kdeXs)), label='CTL', c=plotTrajParams['diagColors'][CTL])\n",
    "  pl.plot(kdeXs, np.exp(kdeMCI.score_samples(kdeXs)), label='MCI', c=plotTrajParams['diagColors'][MCI])\n",
    "  pl.plot(kdeXs, np.exp(kdeAD.score_samples(kdeXs)),  label='AD', c=plotTrajParams['diagColors'][AD])\n",
    "  pl.legend()\n",
    "  fig.show()\n",
    "  fig.savefig('%s/diagHist.png' % (resCurrModel['outFolder']), dpi=100)\n",
    "\n",
    "  ageAtScan = params['ageAtScan']\n",
    "  examDates = params['examDates']\n",
    "\n",
    "  runPred = 'R'\n",
    "  doPlot = 0\n",
    "  predFile = 'tadpolePredD2.npz'\n",
    "\n",
    "  meanBiomkRescale = params['meanBiomkRescale']\n",
    "  stdBiomkRescale = params['stdBiomkRescale']\n",
    "\n",
    "  if runPred == 'R':\n",
    "    for s in range(nrSubjPredSet):\n",
    "\n",
    "      ######### find dps at forecasted months ##########\n",
    "\n",
    "      # find age at forecasted months\n",
    "      subjRowsCurr = partCode == predSetRidUnq[s]\n",
    "\n",
    "      # import pdb\n",
    "      # pdb.set_trace()\n",
    "\n",
    "      # for one timepoint, find the age and the examDate\n",
    "      print('part : ', predSetRidUnq[s], np.sum(subjRowsCurr))\n",
    "      print('part ageAtScan: ', predSetRidUnq[s], ageAtScan[subjRowsCurr][0])\n",
    "\n",
    "      # compute age of subject at every prediction date\n",
    "      ageOneTimept = ageAtScan[subjRowsCurr][0]\n",
    "      examDateOneTimept = datetime.datetime.strptime(examDates[subjRowsCurr][0], '%Y-%m-%d').date()\n",
    "      yearsToPredStartDate = (predStartDate - examDateOneTimept).days/365\n",
    "      ageAtPredDates = ageOneTimept + yearsToPredStartDate + yearsFromPredStartToEachPredDate\n",
    "\n",
    "      # compute dps\n",
    "      subShiftsCurr = resCurrModel['subShifts'][unqPartCodeFromRes == predSetRidUnq[s]]\n",
    "      dpsAtFutForecastDatesCurr = calcDpsGivenAges(ageAtPredDates, subShiftsCurr)\n",
    "\n",
    "      ######## find model predictions for those DPSs ##############3\n",
    "\n",
    "      futureForecastsAdas, futureForecastsVents = calcModelPredAdasVents(dpsAtFutForecastDatesCurr,\n",
    "      thetas, variances, clustProbBC[indexAdas, :].T, clustProbBC[indexVents, :].T, trajFunc)\n",
    "\n",
    "      # add subject-specific intercept to the predictions, is subject has data\n",
    "      # warning: can contain NaNs and even be NaN in all entries.\n",
    "      adasDataCurrSubj = data[subjRowsCurr, indexAdas]\n",
    "      ventsDataCurrSubj = data[subjRowsCurr, indexVents]\n",
    "\n",
    "      ageCurrVisits = ageAtScan[subjRowsCurr]\n",
    "      dpsSubjCurrVisits = calcDpsGivenAges(ageCurrVisits, subShiftsCurr)\n",
    "      currVisitsPredAdas, currVisitsPredVents = calcModelPredAdasVents(dpsSubjCurrVisits, thetas,\n",
    "        variances, clustProbBC[indexAdas, :].T, clustProbBC[indexVents, :].T, trajFunc)\n",
    "\n",
    "      futureForecastsAdas = addSubjIntercept(dpsAtFutForecastDatesCurr, futureForecastsAdas,\n",
    "        adasDataCurrSubj, currVisitsPredAdas)\n",
    "      futureForecastsVents = addSubjIntercept(dpsAtFutForecastDatesCurr, futureForecastsVents,\n",
    "        ventsDataCurrSubj, currVisitsPredVents)\n",
    "\n",
    "      # convert predictions back to un-normalised values\n",
    "\n",
    "      predAdasNotNorm = futureForecastsAdas * stdBiomkRescale[indexAdas] + meanBiomkRescale[indexAdas]\n",
    "      predVentsNotNorm = futureForecastsVents * stdBiomkRescale[indexVents] + meanBiomkRescale[indexVents]\n",
    "\n",
    "      predAdasAllSubj[s, :, :] = predAdasNotNorm\n",
    "      predAdasAllSubj[s, :, 1] = predAdasNotNorm[:,2] # need invert lower& upper bounds due to sign change\n",
    "      predAdasAllSubj[s, :, 2] = predAdasNotNorm[:,1]\n",
    "\n",
    "      predVentsAllSubj[s, :, :] = predVentsNotNorm\n",
    "      predVentsAllSubj[s, :, 1] = predVentsNotNorm[:,2]\n",
    "      predVentsAllSubj[s, :, 2] = predVentsNotNorm[:,1]\n",
    "\n",
    "      # print('predAdasNotNorm', predAdasNotNorm[0,:])\n",
    "      # print(adsa)\n",
    "\n",
    "      adasDataCurrSubjUnnorm = adasDataCurrSubj * stdBiomkRescale[indexAdas] + meanBiomkRescale[indexAdas]\n",
    "      ventsDataCurrSubjUnnorm = ventsDataCurrSubj* stdBiomkRescale[indexVents] + meanBiomkRescale[indexVents]\n",
    "\n",
    "      ctlLik = np.exp(kdeCTL.score_samples(dpsAtFutForecastDatesCurr.reshape(-1,1)))\n",
    "      mciLik = np.exp(kdeMCI.score_samples(dpsAtFutForecastDatesCurr.reshape(-1,1)))\n",
    "      adLik = np.exp(kdeAD.score_samples(dpsAtFutForecastDatesCurr.reshape(-1,1)))\n",
    "\n",
    "      sumLik = ctlLik + mciLik + adLik\n",
    "\n",
    "      predDiagAllSubj[s, :, 0] = ctlLik/sumLik\n",
    "      predDiagAllSubj[s, :, 1] = mciLik/sumLik\n",
    "      predDiagAllSubj[s, :, 2] = adLik/sumLik\n",
    "\n",
    "\n",
    "\n",
    "      if doPlot:\n",
    "        if args.leaderboard:\n",
    "          lb4Data = pd.read_csv('TADPOLE_LB4.csv')\n",
    "          lb4Data['CognitiveAssessmentDate'] = [datetime.datetime.strptime(x, '%Y-%m-%d') for x in lb4Data['CognitiveAssessmentDate']]\n",
    "          lb4Data['ScanDate'] = [datetime.datetime.strptime(x, '%Y-%m-%d').date() for x in lb4Data['ScanDate']]\n",
    "          mapping = {'CN': 0, 'MCI': 1, 'AD': 2}\n",
    "          lb4Data.replace({'Diagnosis': mapping}, inplace=True)\n",
    "\n",
    "          currSubjMaskLB4 = lb4Data.RID == predSetRidUnq[s]\n",
    "          adasLB4CurrSubj = lb4Data.ADAS13[currSubjMaskLB4]\n",
    "          ventsLB4CurrSubj = lb4Data.Ventricles[currSubjMaskLB4]\n",
    "          diagLB4CurrSubj = lb4Data.Diagnosis[currSubjMaskLB4]\n",
    "\n",
    "          datesLB4CurrSubj = lb4Data['CognitiveAssessmentDate'][currSubjMaskLB4]\n",
    "\n",
    "          yearsFromRefDateToLB4Dates = np.array([(d.date() - examDateOneTimept).days/365 for d in datesLB4CurrSubj])\n",
    "          ageAtLB4datesCurrSubj = ageOneTimept + yearsFromRefDateToLB4Dates\n",
    "\n",
    "          lb4Params = dict(adasLB4CurrSubj=adasLB4CurrSubj, ventsLB4CurrSubj=ventsLB4CurrSubj,\n",
    "            diagLB4CurrSubj=diagLB4CurrSubj, ageAtLB4datesCurrSubj=ageAtLB4datesCurrSubj)\n",
    "\n",
    "        else:\n",
    "          lb4Params = None\n",
    "\n",
    "        plotSubjForecasts(predAdasAllSubj[s, :, :], predVentsAllSubj[s, :, :], predDiagAllSubj[s, :, :]\n",
    "        , ageAtPredDates, adasDataCurrSubjUnnorm, ventsDataCurrSubjUnnorm, ageCurrVisits, lb4Params,\n",
    "          rid=predSetRidUnq[s])\n",
    "\n",
    "    ds = dict(predAdasAllSubj=predAdasAllSubj, predVentsAllSubj=predVentsAllSubj,\n",
    "      predDiagAllSubj=predDiagAllSubj)\n",
    "    pickle.dump(ds, open(predFile, 'wb'),protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "  else:\n",
    "    ds = pickle.load(open(predFile, 'rb'))\n",
    "    predAdasAllSubj = ds['predAdasAllSubj']\n",
    "    predVentsAllSubj = ds['predVentsAllSubj']\n",
    "    predDiagAllSubj = ds['predDiagAllSubj']\n",
    "\n",
    "  return predAdasAllSubj, predVentsAllSubj, predDiagAllSubj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSubjForecasts(predAdasCurrSubj, predVentsCurrSubj, predDiagCurrSubj\n",
    "  , ageAtPredDates, adasDataCurrSubjUnnorm, ventsDataCurrSubjUnnorm, ageCurrVisits, lb4Params, rid):\n",
    "\n",
    "  if lb4Params is not None:\n",
    "    adasLB4CurrSubj = lb4Params['adasLB4CurrSubj']\n",
    "    ventsLB4CurrSubj = lb4Params['ventsLB4CurrSubj']\n",
    "    diagLB4CurrSubj = lb4Params['diagLB4CurrSubj']\n",
    "    ageAtLB4datesCurrSubj = lb4Params['ageAtLB4datesCurrSubj']\n",
    "\n",
    "  pl.figure(3)\n",
    "  ax = pl.subplot(1, 2, 1)\n",
    "  ax.set_title('ADAS RID:%d' % rid)\n",
    "  pl.plot(ageAtPredDates, predAdasCurrSubj)\n",
    "  pl.scatter(ageCurrVisits, adasDataCurrSubjUnnorm, c='b',s=10)\n",
    "  if lb4Params is not None:\n",
    "    pl.scatter(ageAtLB4datesCurrSubj, adasLB4CurrSubj, c='r', s=10)\n",
    "\n",
    "  ax = pl.subplot(1, 2, 2)\n",
    "  ax.set_title('Vents RID:%d' % rid)\n",
    "  pl.plot(ageAtPredDates, predVentsCurrSubj)\n",
    "  pl.scatter(ageCurrVisits, ventsDataCurrSubjUnnorm, c='b', s=10)\n",
    "  if lb4Params is not None:\n",
    "    pl.scatter(ageAtLB4datesCurrSubj, ventsLB4CurrSubj, c='r', s=10)\n",
    "\n",
    "  pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcModelPredAdasVents(dpsPredCurr, thetas, variances, clustProbAdas, clustProbVents, trajFunc):\n",
    "\n",
    "  nrClust = thetas.shape[0]\n",
    "  predCurrSubClustSC = np.zeros((dpsPredCurr.shape[0], nrClust), float)\n",
    "  predCurrSubClustSClower = np.zeros((dpsPredCurr.shape[0], nrClust), float)\n",
    "  predCurrSubClustSCupper = np.zeros((dpsPredCurr.shape[0], nrClust), float)\n",
    "\n",
    "  for c in range(nrClust):\n",
    "    predCurrSubClustSC[:, c] = trajFunc(dpsPredCurr, thetas[c, :])\n",
    "    predCurrSubClustSClower[:, c] = predCurrSubClustSC[:, c] - 0.33 * np.sqrt(variances[c])\n",
    "    predCurrSubClustSCupper[:, c] = predCurrSubClustSC[:, c] + 0.33 * np.sqrt(variances[c])\n",
    "\n",
    "  # from the predictions of each cluster trajectories, predict traj of ADAS and Vents\n",
    "  # using the probabilities of ADAS/Vents of being assigned to each cluster\n",
    "  futureForecastsAdas = np.zeros((predCurrSubClustSC.shape[0],3))\n",
    "  futureForecastsVents = np.zeros((predCurrSubClustSC.shape[0],3))\n",
    "\n",
    "  futureForecastsAdas[:,0] = np.dot(predCurrSubClustSC, clustProbAdas)\n",
    "  futureForecastsVents[:,0] = np.dot(predCurrSubClustSC, clustProbVents)\n",
    "\n",
    "  futureForecastsAdas[:,1] = np.dot(predCurrSubClustSClower, clustProbAdas)\n",
    "  futureForecastsVents[:,1] = np.dot(predCurrSubClustSClower, clustProbVents)\n",
    "\n",
    "  futureForecastsAdas[:,2] = np.dot(predCurrSubClustSCupper, clustProbAdas)\n",
    "  futureForecastsVents[:,2] = np.dot(predCurrSubClustSCupper, clustProbVents)\n",
    "\n",
    "  return futureForecastsAdas, futureForecastsVents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcDpsGivenAges(ageAtPredDates, subShiftsCurr):\n",
    "\n",
    "  subShiftsPredDates = np.tile(subShiftsCurr, (ageAtPredDates.shape[0], 1))\n",
    "\n",
    "  #print('subShiftsPredDates', subShiftsPredDates.shape)\n",
    "  #print('ageAtPredDates', ageAtPredDates.shape)\n",
    "  assert subShiftsPredDates.shape[0] == ageAtPredDates.shape[0]\n",
    "  assert subShiftsPredDates.shape[1] == 2\n",
    "\n",
    "  dpsPredCurr = VoxelDPM.calcDpsNo1array(subShiftsPredDates, ageAtPredDates)\n",
    "\n",
    "  return dpsPredCurr\n",
    "\n",
    "def addSubjIntercept(dpsT, futurePredictions, dataCurrSubjT, modelPredExistingVisits):\n",
    "\n",
    "  if np.isnan(dataCurrSubjT).all():\n",
    "    # no data available cur current subject, leave as population estimate\n",
    "    return futurePredictions\n",
    "  else:\n",
    "    # data is\n",
    "    return futurePredictions + (np.nanmean(dataCurrSubjT) - np.mean(modelPredExistingVisits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeTadpoleSubmission(predAdasAllSubj, predVentsAllSubj, predDiagAllSubj, outputFile,\n",
    "  nrMonthsToPred, predStartDate, params):\n",
    "\n",
    "  predInd = params['predInd']\n",
    "  predSetRidUnq = np.unique(predInd)\n",
    "  #print('Writing forecast to file %s' % outputFile)\n",
    "  submission_table = pd.DataFrame()\n",
    "  nrSubjPredSet = predSetRidUnq.shape[0]\n",
    "  # * Repeated matrices - compare with submission template\n",
    "  submission_table['RID'] = predSetRidUnq.repeat(nrMonthsToPred)\n",
    "  submission_table['Forecast Month'] = np.tile(range(1, nrMonthsToPred + 1),\n",
    "    (nrSubjPredSet, 1)).flatten()\n",
    "\n",
    "  from dateutil.relativedelta import relativedelta\n",
    "  endDate = predStartDate + relativedelta(months = +nrMonthsToPred - 1)\n",
    "  ForecastDates = [predStartDate]\n",
    "  while ForecastDates[-1] < endDate:\n",
    "    ForecastDates.append(ForecastDates[-1] + relativedelta(months = +1))\n",
    "\n",
    "  ForecastDatesStrings = [datetime.datetime.strftime(d, '%Y-%m') for d in ForecastDates]\n",
    "  submission_table['Forecast Date'] = np.tile(ForecastDatesStrings, (nrSubjPredSet, 1)).flatten()\n",
    "  # * Pre-fill forecast data, encoding missing data as NaN\n",
    "  nanColumn = np.repeat(np.nan, submission_table.shape[0])\n",
    "  submission_table['CN relative probability'] = nanColumn\n",
    "  submission_table['MCI relative probability'] = nanColumn\n",
    "  submission_table['AD relative probability'] = nanColumn\n",
    "  submission_table['ADAS13'] = nanColumn\n",
    "  submission_table['ADAS13 50% CI lower'] = nanColumn\n",
    "  submission_table['ADAS13 50% CI upper'] = nanColumn\n",
    "  submission_table['Ventricles_ICV'] = nanColumn\n",
    "  submission_table['Ventricles_ICV 50% CI lower'] = nanColumn\n",
    "  submission_table['Ventricles_ICV 50% CI upper'] = nanColumn\n",
    "\n",
    "  # *** Paste in month-by-month forecasts **\n",
    "  # * 1. Clinical status\n",
    "  submission_table['CN relative probability'] = predDiagAllSubj[:, :, 0].flatten()\n",
    "  submission_table['MCI relative probability'] = predDiagAllSubj[:, :, 1].flatten()\n",
    "  submission_table['AD relative probability'] = predDiagAllSubj[:, :, 2].flatten()\n",
    "  # * 2. ADAS13 score\n",
    "  submission_table['ADAS13'] = predAdasAllSubj[:, :, 0].flatten()\n",
    "  submission_table['ADAS13 50% CI lower'] = predAdasAllSubj[:, :, 1].flatten()\n",
    "  submission_table['ADAS13 50% CI upper'] = predAdasAllSubj[:, :, 2].flatten()\n",
    "  # * 3. Ventricles volume (normalised by intracranial volume)\n",
    "  submission_table['Ventricles_ICV'] = predVentsAllSubj[:, :, 0].flatten()\n",
    "  submission_table['Ventricles_ICV 50% CI lower'] = predVentsAllSubj[:, :, 1].flatten()\n",
    "  submission_table['Ventricles_ICV 50% CI upper'] = predVentsAllSubj[:, :, 2].flatten()\n",
    "\n",
    "  submission_table.to_csv(outputFile, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAllExpTADPOLE(params, expName, dpmBuilder):\n",
    "  \"\"\" runs all experiments\"\"\"\n",
    "\n",
    "  res = {}\n",
    "\n",
    "  params['patientID'] = AD\n",
    "  params['excludeID'] = -1\n",
    "  params['excludeXvalidID'] = []\n",
    "  params['excludeStaging'] = [-1]\n",
    "  params['anchorID'] = MCI\n",
    "\n",
    "  # run if this is the master   process or nrProcesses is 1\n",
    "  unluckyProc = (np.mod(params['currModel'] - 1, params['nrProcesses']) == params['runIndex'] - 1)\n",
    "  unluckyOrNoParallel = unluckyProc or (params['nrProcesses'] == 1) or params['masterProcess']\n",
    "\n",
    "  if unluckyOrNoParallel:\n",
    "    dpmObj, res['std'] = evaluationFramework.runStdDPM(params, expName, dpmBuilder, params['runPartMain'])\n",
    "\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "loading data file\n",
      "d2Ind [   2    8   15   21   23   31   51   55   56   58   59   61   69   72\n",
      "   74   89   96  101  106  112  113  120  123  125  126  127  135  138\n",
      "  142  150  156  159  166  173  178  186  200  205  210  214  217  225\n",
      "  229  232  257  259  260  272  276  295  296  298  303  311  315  331\n",
      "  337  359  361  376  377  378  382  384  408  413  416  419  420  441\n",
      "  454  467  473  498  501  505  519  520  522  545  552  553  555  557\n",
      "  558  563  566  572  602  605  610  618  626  637  658  668  671  677\n",
      "  679  680  684  685  686  697  698  715  717  722  731  734  741  746\n",
      "  751  752  767  778  800  802  824  830  835  842  843  863  887  896\n",
      "  906  907  908  914  919  920  923  925  926  934  969  981  984  985\n",
      "  989  997 1016 1023 1030 1032 1034 1043 1045 1046 1052 1057 1072 1074\n",
      " 1078 1080 1098 1106 1122 1123 1155 1169 1186 1187 1190 1195 1203 1206\n",
      " 1212 1222 1232 1243 1249 1250 1255 1256 1261 1268 1280 1286 1300 1331\n",
      " 1346 1351 1352 1407 1408 1414 1417 1418 1427 2002 2007 2018 2022 2036\n",
      " 2037 2043 2045 2052 2055 2060 2061 2068 2072 2073 2079 2083 2087 2093\n",
      " 2106 2109 2116 2119 2121 2123 2124 2130 2133 2146 2148 2150 2151 2155\n",
      " 2164 2167 2168 2180 2182 2183 2184 2185 2187 2191 2195 2196 2200 2201\n",
      " 2205 2208 2213 2216 2219 2220 2225 2233 2234 2238 2239 2240 2245 2247\n",
      " 2249 2263 2264 2274 2284 2301 2304 2307 2308 2315 2316 2332 2333 2336\n",
      " 2347 2357 2360 2363 2367 2373 2374 2376 2378 2379 2380 2389 2391 2392\n",
      " 2394 2395 2396 2403 2405 2407 4003 4004 4005 4009 4012 4014 4015 4018\n",
      " 4020 4021 4024 4028 4030 4034 4035 4036 4037 4039 4041 4042 4043 4050\n",
      " 4051 4058 4059 4060 4061 4063 4066 4067 4071 4072 4073 4075 4076 4077\n",
      " 4080 4081 4082 4084 4086 4089 4090 4092 4093 4094 4097 4100 4102 4105\n",
      " 4114 4115 4119 4120 4121 4122 4125 4127 4128 4133 4136 4138 4139 4143\n",
      " 4146 4148 4149 4150 4151 4155 4158 4159 4160 4162 4164 4167 4169 4170\n",
      " 4171 4172 4173 4175 4176 4177 4179 4184 4186 4187 4188 4189 4195 4197\n",
      " 4198 4199 4200 4205 4206 4208 4210 4211 4212 4213 4214 4215 4216 4217\n",
      " 4219 4220 4222 4223 4224 4225 4226 4229 4232 4234 4235 4240 4241 4243\n",
      " 4245 4250 4251 4254 4255 4256 4258 4260 4262 4263 4264 4266 4268 4269\n",
      " 4270 4271 4272 4275 4276 4277 4278 4279 4281 4282 4287 4288 4290 4291\n",
      " 4292 4293 4294 4299 4300 4301 4302 4303 4307 4308 4309 4310 4311 4312\n",
      " 4313 4320 4324 4328 4331 4332 4335 4338 4339 4340 4343 4345 4346 4348\n",
      " 4349 4350 4351 4352 4354 4356 4357 4359 4360 4362 4363 4365 4367 4369\n",
      " 4371 4372 4376 4377 4380 4381 4382 4383 4384 4385 4386 4387 4388 4389\n",
      " 4390 4391 4393 4394 4395 4396 4399 4400 4401 4402 4404 4405 4408 4410\n",
      " 4414 4415 4417 4419 4420 4421 4422 4423 4424 4426 4427 4428 4429 4430\n",
      " 4431 4432 4433 4434 4438 4441 4442 4443 4444 4446 4447 4448 4449 4453\n",
      " 4455 4458 4463 4464 4465 4466 4468 4469 4473 4475 4482 4483 4485 4488\n",
      " 4489 4491 4496 4498 4499 4502 4503 4506 4507 4510 4512 4513 4514 4515\n",
      " 4516 4517 4520 4521 4522 4531 4536 4538 4539 4540 4542 4543 4545 4547\n",
      " 4548 4552 4553 4555 4556 4557 4558 4559 4562 4564 4571 4576 4577 4578\n",
      " 4579 4580 4582 4585 4586 4587 4589 4590 4594 4597 4598 4603 4604 4605\n",
      " 4607 4609 4611 4612 4613 4614 4615 4616 4620 4621 4623 4624 4625 4626\n",
      " 4629 4630 4631 4632 4635 4636 4637 4638 4643 4644 4645 4649 4653 4654\n",
      " 4659 4661 4668 4671 4672 4674 4675 4676 4678 4679 4696 4706 4707 4708\n",
      " 4711 4712 4713 4714 4715 4718 4719 4720 4721 4722 4723 4732 4736 4737\n",
      " 4739 4741 4742 4743 4744 4746 4750 4755 4756 4757 4762 4764 4765 4767\n",
      " 4769 4772 4774 4777 4780 4782 4791 4792 4793 4795 4796 4798 4799 4801\n",
      " 4803 4804 4806 4807 4809 4813 4815 4816 4817 4820 4823 4832 4835 4838\n",
      " 4842 4843 4844 4849 4855 4856 4857 4858 4862 4869 4871 4872 4873 4876\n",
      " 4877 4878 4883 4885 4888 4889 4891 4892 4893 4894 4896 4897 4898 4899\n",
      " 4900 4902 4903 4907 4910 4917 4918 4919 4920 4922 4924 4925 4926 4928\n",
      " 4929 4936 4938 4940 4941 4944 4945 4951 4952 4954 4955 4959 4960 4962\n",
      " 4966 4974 4976 4980 4986 4987 4989 4990 4994 4997 5000 5004 5005 5007\n",
      " 5014 5016 5023 5027 5028 5031 5037 5038 5040 5047 5056 5057 5058 5059\n",
      " 5062 5063 5066 5067 5070 5078 5079 5082 5083 5091 5093 5095 5096 5097\n",
      " 5099 5100 5102 5106 5109 5110 5113 5118 5119 5120 5123 5124 5125 5126\n",
      " 5127 5130 5131 5132 5135 5137 5140 5141 5142 5147 5148 5153 5154 5157\n",
      " 5158 5159 5160 5166 5167 5169 5170 5171 5175 5176 5177 5178 5184 5185\n",
      " 5187 5193 5194 5195 5197 5198 5199 5200 5202 5203 5204 5209 5210 5212\n",
      " 5213 5218 5219 5222 5227 5228 5230 5234 5236 5237 5241 5242 5243 5244\n",
      " 5248 5253 5256 5258 5259 5261 5265 5266 5267 5269 5271 5272 5273 5275\n",
      " 5277 5278 5280 5282 5283 5285 5287 5288 5289 5290 5292 5294 5295 5296] (896,)\n"
     ]
    }
   ],
   "source": [
    "def printResADNIthick(modelNames, res, plotTrajParams):\n",
    "  #nrModels = len(modelNames)\n",
    "\n",
    "  # dinamicModelName = 'VWDPMLinear'\n",
    "  # staticModelName = 'VWDPMLinearStatic'\n",
    "  # dinamicModelName = 'VDPM_MRF'\n",
    "  # staticModelName = 'VWDPMStatic'\n",
    "  # noDPSModelName = 'VDPMNoDPS'\n",
    "\n",
    "  print('##### biomk prediction ######')\n",
    "  nrModels = len(modelNames)\n",
    "  pred = list(range(nrModels))\n",
    "  predMean = list(range(nrModels))\n",
    "  predStd = list(range(nrModels))\n",
    "  for m in range(nrModels):\n",
    "    pred[m] = res[m]['cogCorr']['predStats']\n",
    "    predMean[m] = np.nanmean(pred[m])\n",
    "    predStd[m] = np.nanstd(pred[m])\n",
    "\n",
    "  for m in range(nrModels):\n",
    "    print('%s predAllFolds' % modelNames[m], pred[m])\n",
    "  for m in range(nrModels):\n",
    "    print('%s predMean' % modelNames[m], predMean[m])\n",
    "  for m in range(nrModels):\n",
    "    print('%s predStd' % modelNames[m], predStd[m])\n",
    "\n",
    "  stats = list(range(nrModels))\n",
    "  print('\\n##### correlation with cog tests ######')\n",
    "  for m in range(nrModels):\n",
    "    stats[m] = res[m]['cogCorr']['statsAllFolds']  # shape (NR_FOLDS, 2*NR_COG_TESTS)\n",
    "    #print('stats:', stats[m])\n",
    "    print(modelNames[m],end='')\n",
    "    meanStats = np.nanmean(stats[m], 0)\n",
    "    stdStats = np.nanstd(stats[m], 0)\n",
    "    for i in range(meanStats.shape[0]):\n",
    "      print('%.2f +/- %.2f' % (meanStats[i], stdStats[i]), end='')\n",
    "    print('')\n",
    "\n",
    "  plotScoresHist(scores = pred, labels=modelNames)\n",
    "\n",
    "  nrCogStats = stats[0].shape[1]\n",
    "\n",
    "  # perform paired t-test, as the same cross-validation folds have been used in both cases\n",
    "  tStats = np.zeros(nrCogStats,float)\n",
    "  pVals = np.zeros(nrCogStats,float)\n",
    "  for t in range(nrCogStats):\n",
    "    tStats[t], pVals[t] = scipy.stats.ttest_rel(stats[0][:,t], stats[0][:,t])\n",
    "\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "  if args.modelToRun:\n",
    "    modelToRun = args.modelToRun\n",
    "  elif args.models:\n",
    "    modelToRun = np.array(np.arange(args.models))\n",
    "    print(modelToRun)\n",
    "  else:\n",
    "    raise ValueError('need to set either --models or --firstModel & --lastModel')\n",
    "\n",
    "  launchTadpole(args.runIndex, args.nrProc, modelToRun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
