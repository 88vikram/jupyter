{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from socket import gethostname\n",
    "from voxCommon_latest import initCommonVoxParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s [%(process)d] %(levelname)-8s \"\n",
    "    \"%(name)s,%(lineno)s\\t%(message)s\"\n",
    ")\n",
    "logging.getLogger().setLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"runIndex\": 1,\n",
    "    \"nrProc\": 1,\n",
    "    \"models\": 13,\n",
    "    \"nrOuterIt\": 5,\n",
    "    \"nrInnerIt\": 1,\n",
    "    \"nrClust\": 12,\n",
    "    \"initClustering\": \"k-means\",\n",
    "    \"rangeFactor\": 1,\n",
    "    \"informPrior\": 0,\n",
    "    \"leaderboard\": 0,\n",
    "    \"agg\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.get(\"agg\"):\n",
    "    import matplotlib\n",
    "\n",
    "    matplotlib.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluationFramework\n",
    "from voxelDPM import *\n",
    "from aux import *\n",
    "from adniCommon import *\n",
    "from env import *\n",
    "import pandas as pd\n",
    "import PlotterVDPM\n",
    "import VDPMNan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, plotTrajParams = initCommonVoxParams(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrajParams[\"legendCols\"] = 4\n",
    "plotTrajParams[\"diagColors\"] = {CTL: \"b\", MCI: \"g\", AD: \"r\", -1: \"y\"}\n",
    "plotTrajParams[\"diagLabels\"] = {CTL: \"CTL\", MCI: \"MCI\", AD: \"AD\", -1: \"N/A\"}\n",
    "plotTrajParams[\"ylimitsRandPoints\"] = (-5, 5)\n",
    "plotTrajParams[\"diagNrs\"] = [CTL, MCI, AD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrajParams[\"SubfigClustMaxWinSize\"] = (\n",
    "    1300,\n",
    "    plotTrajParams[\"SubfigClustMaxWinSize\"][1],\n",
    ")\n",
    "plotTrajParams[\"Clust3DMaxWinSize\"] = (900, 600)\n",
    "# plotTrajParams['ylimTrajWeightedDataMean'] = (-3,2)\n",
    "plotTrajParams[\"ylimTrajSamplesInOneNoData\"] = (-2.5, 1.5)\n",
    "plotTrajParams[\"biomkAxisLabel\"] = \"Cortical Thickness Z-score\"\n",
    "plotTrajParams[\"biomkWasInversed\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "refDate = datetime.date(2000, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanTadpoleData(df):\n",
    "    logging.info(\"Start cleanTadpoleData\")\n",
    "\n",
    "    df.loc[df.RAVLT_learning < 0, \"RAVLT_learning\"] = np.nan\n",
    "    df.loc[df.RAVLT_forgetting < 0, \"RAVLT_forgetting\"] = np.nan\n",
    "    df.loc[df.RAVLT_perc_forgetting < 0, \"RAVLT_perc_forgetting\"] = np.nan\n",
    "\n",
    "    petCols = list(\n",
    "        df.loc[:, \"HIPPL01_BAIPETNMRC_09_12_16\":\"MCSUVRCERE_BAIPETNMRC_09_12_16\"]\n",
    "    )\n",
    "    for c in petCols:\n",
    "        df.loc[df[c] == \"-4\", c] = np.nan\n",
    "\n",
    "    logging.info(\"End cleanTadpoleData\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateDiffToMonths(diff):\n",
    "    return diff.days / (365.0 / 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseTadpoleData(df):\n",
    "    logging.info(\"Start parseTadpoleData\")\n",
    "\n",
    "    cols = (\n",
    "        list(df.loc[:, \"FDG\":\"EcogSPTotal\"])\n",
    "        + list(df.loc[:, \"Ventricles\":\"MidTemp\"])\n",
    "        + list(\n",
    "            df.loc[\n",
    "                :,\n",
    "                \"ST101SV_UCSFFSL_02_01_16_UCSFFSL51ALL_08_01_16\":\"ST9SV_UCSFFSL_02_01_16_UCSFFSL51ALL_08_01_16\",\n",
    "            ]\n",
    "        )\n",
    "        + list(\n",
    "            df.loc[\n",
    "                :,\n",
    "                \"ST101SV_UCSFFSX_11_02_15_UCSFFSX51_08_01_16\":\"ST9SV_UCSFFSX_11_02_15_UCSFFSX51_08_01_16\",\n",
    "            ]\n",
    "        )\n",
    "        + list(\n",
    "            df.loc[:, \"HIPPL01_BAIPETNMRC_09_12_16\":\"MCSUVRCERE_BAIPETNMRC_09_12_16\"]\n",
    "        )\n",
    "        + list(\n",
    "            df.loc[\n",
    "                :,\n",
    "                \"CEREBELLUMGREYMATTER_UCBERKELEYAV45_10_17_16\":\"WM_HYPOINTENSITIES_SIZE_UCBERKELEYAV45_10_17_16\",\n",
    "            ]\n",
    "        )\n",
    "        + list(\n",
    "            df.loc[\n",
    "                :,\n",
    "                \"CEREBELLUMGREYMATTER_UCBERKELEYAV1451_10_17_16\":\"WM_HYPOINTENSITIES_SIZE_UCBERKELEYAV1451_10_17_16\",\n",
    "            ]\n",
    "        )\n",
    "        + list(df.loc[:, \"FA_CST_L_DTIROI_04_30_14\":\"AD_SUMFX_DTIROI_04_30_14\"])\n",
    "        + list(df.loc[:, \"ABETA_UPENNBIOMK9_04_19_17\":\"PTAU_UPENNBIOMK9_04_19_17\"])\n",
    "    )\n",
    "\n",
    "    # TODO: re-process data more, continue form here: change AV45 -> AV45/SIZE of ROI\n",
    "    # print('cols', cols)\n",
    "    # filter out the FS cols with Standard deviation of volumes, cort thickness, etc ... Only keep average\n",
    "    colsFilt = []\n",
    "    for col in cols:\n",
    "        if col[:2] == \"ST\" and (col[5] == \"S\" or col[6] == \"S\"):\n",
    "            continue\n",
    "\n",
    "        colsFilt += [col]\n",
    "\n",
    "    # print(ads)\n",
    "    # print(df.D1)\n",
    "    # print(df.shape)\n",
    "    d2Ind = df.RID[df.loc[:, \"D2\"] == 1].values\n",
    "\n",
    "    print(\"d2Ind\", np.unique(d2Ind), np.unique(d2Ind).shape)\n",
    "\n",
    "    df[cols] = df[cols].apply(pd.to_numeric, errors=\"coerce\", axis=1)\n",
    "    pickle.dump(\n",
    "        dict(df=df), open(\"tadpoleCleanDf.npz\", \"wb\"), protocol=pickle.HIGHEST_PROTOCOL\n",
    "    )\n",
    "    df = pickle.load(open(\"tadpoleCleanDf.npz\", \"rb\"))[\"df\"]\n",
    "\n",
    "    # normalise ventricles by ICV\n",
    "    df[\"Ventricles\"] = df[\"Ventricles\"] / df[\"ICV\"]\n",
    "\n",
    "    data = df.values(columns=cols)\n",
    "\n",
    "    # convert diagnoses such as 'MCI to Dementia' to 'Dementia', etc ...\n",
    "    # ctlDxchange = [1, 7, 9] mciDxchange = [2, 4, 8] adDxChange = [3, 5, 6]\n",
    "    mapping = {1: CTL, 7: CTL, 9: CTL, 2: MCI, 4: MCI, 8: MCI, 3: AD, 5: AD, 6: AD}\n",
    "    # df.replace({'DXCHANGE': mapping}, inplace=True)\n",
    "    df[\"DXCHANGE\"] = df[\"DXCHANGE\"].map(mapping)\n",
    "    diag = df[\"DXCHANGE\"].values()\n",
    "\n",
    "    examDates = df.EXAMDATE.values()\n",
    "    df[\"EXAMDATE\"] = pd.to_datetime(df[\"EXAMDATE\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "    dataDf = df[cols]\n",
    "    dataDf.to_csv(\"tadpoleCleanDf.csv\")\n",
    "\n",
    "    # build numpy string array\n",
    "    nrCols = len(cols)\n",
    "    labels = np.ndarray((nrCols,), dtype=\"S100\")\n",
    "    for c in range(nrCols):\n",
    "        labels[c] = cols[c]\n",
    "\n",
    "    partCode = df.RID.values()\n",
    "\n",
    "    unqPartCode = np.unique(partCode)\n",
    "    nrUnqSubj = len(unqPartCode)\n",
    "\n",
    "    ageAtScan = np.zeros(partCode.shape, np.float)\n",
    "    scanTimepts = np.zeros(partCode.shape, np.float)\n",
    "\n",
    "    for s in range(nrUnqSubj):\n",
    "        subjRowsCurr = df.RID == unqPartCode[s]\n",
    "        ageAtBlCurr = df.AGE[subjRowsCurr]\n",
    "        examDatesCurr = df.EXAMDATE[subjRowsCurr]\n",
    "\n",
    "        minInd = np.argmin(examDatesCurr)\n",
    "        yearsDiffs = [(d - examDatesCurr[minInd]).days / 365 for d in examDatesCurr]\n",
    "\n",
    "        ageAtScan[subjRowsCurr] = ageAtBlCurr + yearsDiffs\n",
    "\n",
    "        scanTimepts[subjRowsCurr] = np.argsort(np.argsort(yearsDiffs))\n",
    "\n",
    "        sortedVisitsCurr = np.argsort(yearsDiffs)\n",
    "        diagCurrSorted = diag[subjRowsCurr][sortedVisitsCurr]\n",
    "\n",
    "        notNanDiags = [d for d in diagCurrSorted if not np.isnan(d)]\n",
    "\n",
    "        diagCurrSortedFilled = np.copy(diagCurrSorted)\n",
    "\n",
    "        if len(notNanDiags) == 0:\n",
    "            # set the subject diag as -1 if there is absolutely no diagnosis\n",
    "            diagCurrSortedFilled[0] = -1\n",
    "        else:\n",
    "            if np.isnan(diagCurrSortedFilled[0]):\n",
    "                diagCurrSortedFilled[0] = notNanDiags[0]\n",
    "\n",
    "            for v in range(1, len(sortedVisitsCurr)):\n",
    "                if np.isnan(diagCurrSortedFilled[v]):\n",
    "                    diagCurrSortedFilled[v] = diagCurrSortedFilled[v - 1]\n",
    "\n",
    "        diagFilledInOrigOrder = diagCurrSortedFilled[np.argsort(sortedVisitsCurr)]\n",
    "\n",
    "        diag[subjRowsCurr] = diagFilledInOrigOrder\n",
    "\n",
    "    # compute number of months since Jan 2000 for each EXAMDATEs\n",
    "    monthsSinceRefTime = np.zeros(partCode.shape, np.float)\n",
    "\n",
    "    for r in range(df.RID.shape[0]):\n",
    "        monthsSinceRefTime[r] = dateDiffToMonths(df.EXAMDATE[r].date() - refDate)\n",
    "\n",
    "    assert not np.isnan(ageAtScan).any()\n",
    "    assert not np.isnan(diag).any()\n",
    "    assert not np.isnan(scanTimepts).any()\n",
    "    assert not np.isnan(partCode).any()\n",
    "    assert not np.isnan(monthsSinceRefTime).any()\n",
    "\n",
    "    logging.info(\"End parseTadpoleData\")\n",
    "    return (\n",
    "        data,\n",
    "        diag,\n",
    "        labels,\n",
    "        scanTimepts,\n",
    "        partCode,\n",
    "        ageAtScan,\n",
    "        dataDf,\n",
    "        monthsSinceRefTime,\n",
    "        examDates,\n",
    "        d2Ind,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeBiomksDecr(data, diag, labels):\n",
    "    logging.info(\"Start makeBiomksDecr\")\n",
    "\n",
    "    assert data.shape[0] == diag.shape[0]\n",
    "\n",
    "    # perform t-test on every voxel, sort them by p-values\n",
    "    pVals = scipy.stats.ttest_ind(\n",
    "        data[diag == CTL, :], data[diag == AD, :], nan_policy=\"omit\"\n",
    "    )[1]\n",
    "\n",
    "    sortedInd = np.argsort(pVals)\n",
    "    print(\"sortedInd\", sortedInd)\n",
    "\n",
    "    print(\"data[diag == CTL, :]\", data[diag == CTL, :])\n",
    "    meanCTL = np.nanmean(data[diag == CTL, :], axis=0)\n",
    "    meanAD = np.nanmean(data[diag == AD, :], axis=0)\n",
    "    stdCTL = np.nanstd(data[diag == CTL, :], axis=0)\n",
    "    stdAD = np.nanstd(data[diag == AD, :], axis=0)\n",
    "\n",
    "    # record which biomarkers have had their sign flipped. Multiply this vector\n",
    "    # with the scale from the normalisation with controls that we did earlier.\n",
    "    biomkScaleExtra = np.ones(pVals.shape)\n",
    "\n",
    "    for b in sortedInd:\n",
    "\n",
    "        if (pVals[b] < 0.001) and meanAD[b] > meanCTL[b]:\n",
    "            data[:, b] = data[:, b] * (-1)\n",
    "            biomkScaleExtra[b] = -1\n",
    "            # print('flipped sign for %s' % labels[b])\n",
    "\n",
    "    logging.info(\"End makeBiomksDecr\")\n",
    "\n",
    "    return data, sortedInd, biomkScaleExtra, pVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visTadpoleHist(data, diag, age, labels, plotTrajParams, sortedByPvalInd):\n",
    "    \"\"\"\n",
    "  Plots average biomarker value for various ROIs\n",
    "\n",
    "  :param data: NR_CROSS_SUBJ x NR_BIOMK array\n",
    "  :param diag: NR_CROSS_SUBJ x 1\n",
    "  :param age:  NR_CROSS_SUBJ x 1\n",
    "  :param plotTrajParams: dictionary of plotting parameters\n",
    "  :param sortedByPvalInd: ROI indicesof each point on the surface, sorted by p-value (the regions for which we observe the highest differences between CTL and AD apprear first)\n",
    "\n",
    "  :return: figure handle\n",
    "  \"\"\"\n",
    "\n",
    "    logging.info(\"Start visTadpoleHist\")\n",
    "\n",
    "    fig = pl.figure()\n",
    "    nrRows = 3\n",
    "    nrCols = 4\n",
    "    nrBiomkToDisplay = nrRows * nrCols\n",
    "\n",
    "    nrSubj, nrBiomk = data.shape\n",
    "\n",
    "    xs = np.linspace(np.min(age), np.max(age), 100)\n",
    "    diagNrs = plotTrajParams[\"diagNrs\"]\n",
    "\n",
    "    VDPMNaN.makeLongArray(data, scanTimepts, partCode, np.unique(partCode))\n",
    "\n",
    "    for row in range(nrRows):\n",
    "        for col in range(nrCols):\n",
    "            b = row * nrCols + col  # clusterNr\n",
    "            print(\"Plotting biomk:\", b)\n",
    "\n",
    "            if b < nrBiomk:\n",
    "                ax = pl.subplot(nrRows, nrCols, 1 + np.mod(b, nrBiomkToDisplay))\n",
    "                ax.set_title(\"b%d %s\" % (b, labels[b][:10]))\n",
    "\n",
    "                nnMask = np.logical_not(np.isnan(data[:, b]))\n",
    "                dataNotNanS = data[nnMask, b]\n",
    "                diagNotNanS = diag[nnMask]\n",
    "                ageNotNanS = age[nnMask]\n",
    "\n",
    "                print(\"dataNotNanS\", dataNotNanS)\n",
    "                print(\"\\ndiagNotNanS\", diagNotNanS)\n",
    "\n",
    "                for d in range(len(diagNrs)):\n",
    "                    ax.hist(\n",
    "                        dataNotNanS[diagNotNanS == diagNrs[d]],\n",
    "                        bins=20,\n",
    "                        alpha=0.5,\n",
    "                        label=plotTrajParams[\"diagLabels\"][diagNrs[d]],\n",
    "                        color=plotTrajParams[\"diagColors\"][diagNrs[d]],\n",
    "                    )\n",
    "\n",
    "                if col == 0:\n",
    "                    ax.set_ylabel(\"Z-score\")\n",
    "\n",
    "                if row == (nrRows - 1):\n",
    "                    ax.set_xlabel(\"biomk value\")\n",
    "                else:\n",
    "                    ax.set_xticks([])\n",
    "\n",
    "                if b == 0:\n",
    "                    adjustCurrFig(plotTrajParams)\n",
    "                    fig.suptitle(\"indiv points\", fontsize=20)\n",
    "\n",
    "                    h, axisLabels = ax.get_legend_handles_labels()\n",
    "\n",
    "                    legend = pl.figlegend(\n",
    "                        h,\n",
    "                        axisLabels,\n",
    "                        loc=\"lower center\",\n",
    "                        ncol=plotTrajParams[\"legendCols\"],\n",
    "                        labelspacing=0.0,\n",
    "                    )\n",
    "\n",
    "                    mng = pl.get_current_fig_manager()\n",
    "                    mng.resize(*plotTrajParams[\"SubfigVisMaxWinSize\"])\n",
    "\n",
    "    pl.show()\n",
    "\n",
    "    logging.info(\"End visTadpoleHist\")\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visTadpoleSpagetti(\n",
    "    data, diag, age, scanTimepts, partCode, labels, plotTrajParams, sortedByPvalInd\n",
    "):\n",
    "    \"\"\"\n",
    "  Plots average biomarker value for various ROIs\n",
    "\n",
    "  :param data: NR_CROSS_SUBJ x NR_BIOMK array\n",
    "  :param diag: NR_CROSS_SUBJ x 1\n",
    "  :param age:  NR_CROSS_SUBJ x 1\n",
    "  :param plotTrajParams: dictionary of plotting parameters\n",
    "  :param sortedByPvalInd: ROI indicesof each point on the surface, sorted by p-value (the regions for which we observe the highest differences between CTL and AD apprear first)\n",
    "\n",
    "  :return: figure handle\n",
    "  \"\"\"\n",
    "    logging.info(\"Start visTadpoleSpagetti\")\n",
    "\n",
    "    fig = pl.figure()\n",
    "    nrRows = 3\n",
    "    nrCols = 4\n",
    "    nrBiomkToDisplay = nrRows * nrCols\n",
    "\n",
    "    nrSubj, nrBiomk = data.shape\n",
    "\n",
    "    xs = np.linspace(np.min(age), np.max(age), 100)\n",
    "    diagNrs = plotTrajParams[\"diagNrs\"]\n",
    "    # import VDPMNan\n",
    "    unqPartCode = np.unique(partCode)\n",
    "    longData = VDPMNan.VDPMNan.makeLongArray(\n",
    "        None, data, scanTimepts, partCode, unqPartCode\n",
    "    )\n",
    "    longDiag = VDPMNan.VDPMNan.makeLongArray(\n",
    "        None, diag, scanTimepts, partCode, unqPartCode\n",
    "    )\n",
    "    longAge = VDPMNan.VDPMNan.makeLongArray(\n",
    "        None, age, scanTimepts, partCode, unqPartCode\n",
    "    )\n",
    "    nrLongSubj = len(longDiag)\n",
    "\n",
    "    for row in range(nrRows):\n",
    "        for col in range(nrCols):\n",
    "            b = row * nrCols + col  # clusterNr\n",
    "            print(\"Plotting biomk:\", b)\n",
    "\n",
    "            if b < nrBiomk:\n",
    "                ax = pl.subplot(nrRows, nrCols, 1 + np.mod(b, nrBiomkToDisplay))\n",
    "                ax.set_title(\"b%d %s\" % (b, labels[b][:10]))\n",
    "\n",
    "                nnMask = np.logical_not(np.isnan(data[:, b]))\n",
    "                dataNotNanS = data[nnMask, b]\n",
    "                diagNotNanS = diag[nnMask]\n",
    "                ageNotNanS = age[nnMask]\n",
    "\n",
    "                # print('dataNotNanS', dataNotNanS)\n",
    "                # print('diagNotNanS', diagNotNanS)\n",
    "\n",
    "                for s in range(nrLongSubj):\n",
    "                    # print('longAge[s]', longAge[s])\n",
    "                    # print('longData[s][:,b]', longData[s][:,b])\n",
    "                    # print('longDiag[s][0]', longDiag[s][0])\n",
    "                    pl.plot(\n",
    "                        longAge[s],\n",
    "                        longData[s][:, b],\n",
    "                        c=plotTrajParams[\"diagColors\"][longDiag[s][0]],\n",
    "                        label=plotTrajParams[\"diagLabels\"][longDiag[s][0]],\n",
    "                    )\n",
    "\n",
    "                if col == 0:\n",
    "                    ax.set_ylabel(\"biomarker\")\n",
    "\n",
    "                if row == (nrRows - 1):\n",
    "                    ax.set_xlabel(\"age\")\n",
    "                else:\n",
    "                    ax.set_xticks([])\n",
    "\n",
    "                if b == 0:\n",
    "                    adjustCurrFig(plotTrajParams)\n",
    "                    fig.suptitle(\"indiv points\", fontsize=20)\n",
    "\n",
    "                    h, axisLabels = ax.get_legend_handles_labels()\n",
    "\n",
    "                    legend = pl.figlegend(\n",
    "                        h,\n",
    "                        axisLabels,\n",
    "                        loc=\"lower center\",\n",
    "                        ncol=plotTrajParams[\"legendCols\"],\n",
    "                        labelspacing=0.0,\n",
    "                    )\n",
    "\n",
    "                    mng = pl.get_current_fig_manager()\n",
    "                    mng.resize(*plotTrajParams[\"SubfigVisMaxWinSize\"])\n",
    "\n",
    "    pl.show()\n",
    "\n",
    "    logging.info(\"End visTadpoleSpagetti\")\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launchTadpole(runIndex, nrProcesses, modelToRun):\n",
    "    logger.info(\"Start launchTadpole\")\n",
    "\n",
    "    genProcessedDataset = 1\n",
    "\n",
    "    if genProcessedDataset:\n",
    "        if args.get(\"leaderboard\") == 0:\n",
    "            inputFileData = \"data/TADPOLE_D1_D2.csv\"\n",
    "            sys.stdout.flush()\n",
    "            outFileCheckpoint2 = \"tadpoleDf2.npz\"\n",
    "            print(\"loading data file\")\n",
    "            df = pd.read_csv(inputFileData, low_memory=False)\n",
    "            df = cleanTadpoleData(df)\n",
    "            data, diag, labels, scanTimepts, partCode, ageAtScan, dataDf, monthsSinceRefTime, examDates, predInd = parseTadpoleData(\n",
    "                df\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            outFileCheckpoint2 = \"tadpoleDf2Ldb.npz\"\n",
    "            print(\"loading data file\")\n",
    "            inputFileDataD1D2 = \"data/TADPOLE_D1_D2.csv\"\n",
    "            df = pd.read_csv(inputFileDataD1D2, low_memory=False)\n",
    "            df = cleanTadpoleData(df)\n",
    "            inputFileDataLB = \"data/TADPOLE_LB1_LB2.csv\"\n",
    "            dfLB = pd.read_csv(inputFileDataLB, low_memory=False)\n",
    "\n",
    "            data, diag, labels, scanTimepts, partCode, ageAtScan, dataDf, monthsSinceRefTime, examDates, _ = parseTadpoleData(\n",
    "                df\n",
    "            )\n",
    "\n",
    "            filterMaskLB12 = np.logical_or(dfLB.LB1 == 1, dfLB.LB2 == 1)\n",
    "            assert data.shape[0] == dfLB.shape[0]\n",
    "\n",
    "            data = data[filterMaskLB12, :]\n",
    "            diag = diag[filterMaskLB12]\n",
    "            scanTimepts = scanTimepts[filterMaskLB12]\n",
    "            partCode = partCode[filterMaskLB12]\n",
    "            ageAtScan = ageAtScan[filterMaskLB12]\n",
    "            dataDf = dataDf[filterMaskLB12]\n",
    "            dataDf.reset_index(drop=True, inplace=True)\n",
    "            dataDf.reindex(index=range(dataDf.shape[0]))\n",
    "            monthsSinceRefTime = monthsSinceRefTime[filterMaskLB12]\n",
    "            examDates = examDates[filterMaskLB12]\n",
    "            predInd = dfLB.RID[dfLB.LB2 == 1].values()\n",
    "\n",
    "        dataStruct = dict(\n",
    "            data=data,\n",
    "            diag=diag,\n",
    "            labels=labels,\n",
    "            scanTimepts=scanTimepts,\n",
    "            partCode=partCode,\n",
    "            ageAtScan=ageAtScan,\n",
    "            dataDf=dataDf,\n",
    "            monthsSinceRefTime=monthsSinceRefTime,\n",
    "            examDates=examDates,\n",
    "            predInd=predInd,\n",
    "        )\n",
    "        pickle.dump(\n",
    "            dataStruct, open(outFileCheckpoint2, \"wb\"), protocol=pickle.HIGHEST_PROTOCOL\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        if args.get(\"leaderboard\") == 0:\n",
    "            outFileCheckpoint2 = \"tadpoleDf2.npz\"\n",
    "        else:\n",
    "            outFileCheckpoint2 = \"tadpoleDf2Ldb.npz\"\n",
    "\n",
    "    dataStruct = pickle.load(open(outFileCheckpoint2, \"rb\"))\n",
    "    data = dataStruct[\"data\"]\n",
    "    diag = dataStruct[\"diag\"]\n",
    "    labels = dataStruct[\"labels\"]\n",
    "    scanTimepts = dataStruct[\"scanTimepts\"]\n",
    "    partCode = dataStruct[\"partCode\"]\n",
    "    ageAtScan = dataStruct[\"ageAtScan\"]\n",
    "    monthsSinceRefTime = dataStruct[\"monthsSinceRefTime\"]\n",
    "    examDates = dataStruct[\"examDates\"]\n",
    "    predInd = dataStruct[\"predInd\"]\n",
    "\n",
    "    print(\"compiling parameters\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    print(\"diag\", np.unique(diag), diag)\n",
    "\n",
    "    unqPartCode = np.unique(partCode)\n",
    "    nrUnqPart = len(unqPartCode)\n",
    "\n",
    "    controlInd = diag == CTL\n",
    "    stdBiomk = np.nanstd(data[diag == CTL], 0)\n",
    "    biomkMaskCTL = np.isnan(np.nanstd(data[diag == CTL], 0))\n",
    "    biomkMaskAD = np.isnan(np.nanstd(data[diag == AD], 0))\n",
    "    biomkMaskMCI = np.isnan(np.nanstd(data[diag == MCI], 0))\n",
    "    mask = np.logical_or(np.logical_or(biomkMaskCTL, biomkMaskMCI), biomkMaskAD)\n",
    "    # print(ads)\n",
    "    selectedBiomk = np.logical_not(np.logical_or(mask, stdBiomk == 0))\n",
    "\n",
    "    print(data.shape)\n",
    "    data = data[:, selectedBiomk]\n",
    "    labels = labels[selectedBiomk]\n",
    "    pointIndices = np.array(range(data.shape[1]))\n",
    "    stdBiomk = np.nanstd(data[controlInd], 0)\n",
    "    print(data.shape)\n",
    "    # print(ads)\n",
    "\n",
    "    meanCTL = np.nanmean(data[controlInd], 0)  # calculate Z-scores\n",
    "    stdCTL = np.nanstd(data[controlInd], 0)\n",
    "    dataZ = (data - meanCTL[None, :]) / stdCTL[None, :]\n",
    "    data = dataZ\n",
    "\n",
    "    outlierRows, outlierCols = np.where(np.abs(dataZ) > 50)\n",
    "    filterMask = np.ones(data.shape[0], bool)\n",
    "    filterMask[outlierRows] = 0\n",
    "    data = data[filterMask]\n",
    "    diag = diag[filterMask]\n",
    "    scanTimepts = scanTimepts[filterMask]\n",
    "    partCode = partCode[filterMask]\n",
    "    ageAtScan = ageAtScan[filterMask]\n",
    "    monthsSinceRefTime = monthsSinceRefTime[filterMask]\n",
    "    examDates = examDates[filterMask]\n",
    "    meanAgeAtScan = np.mean(ageAtScan.astype(float))\n",
    "    ageAtScanCentered = (ageAtScan - meanAgeAtScan).astype(np.float16)\n",
    "\n",
    "    nrSubj, nrBiomk = data.shape\n",
    "\n",
    "    dataAD = data[diag == AD, :]\n",
    "\n",
    "    data, sortedByPvalInd, biomkScaleExtra, pVals = makeBiomksDecr(data, diag, labels)\n",
    "\n",
    "    stdBiomkRescale = biomkScaleExtra * stdCTL\n",
    "\n",
    "    assert sortedByPvalInd.shape[0] == data.shape[1]\n",
    "\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    global params\n",
    "\n",
    "    params[\"data\"] = data\n",
    "    params[\"diag\"] = diag\n",
    "    params[\"scanTimepts\"] = scanTimepts\n",
    "    params[\"partCode\"] = partCode\n",
    "    params[\"ageAtScan\"] = ageAtScan\n",
    "    params[\n",
    "        \"initShift\"\n",
    "    ] = ageAtScanCentered  # initialise time shifts (betas) to (age - meanAge)\n",
    "    params[\"biomkDir\"] = DECR\n",
    "    params[\"modelToRun\"] = modelToRun\n",
    "    params[\"datasetFull\"] = \"tadpole\"\n",
    "    params[\"labels\"] = labels\n",
    "    params[\"predInd\"] = predInd\n",
    "    params[\"examDates\"] = examDates\n",
    "\n",
    "    print(\"outFileCheckpoint2\", outFileCheckpoint2)\n",
    "    print(\"d2Ind\", np.unique(predInd), np.unique(predInd).shape)\n",
    "\n",
    "    unqPartCode = np.unique(params[\"partCode\"])\n",
    "    nrPartToSample = 30\n",
    "    np.random.seed(3)\n",
    "    selectedPartCode = np.random.choice(unqPartCode, nrPartToSample)\n",
    "    dataIndices = np.in1d(params[\"partCode\"], selectedPartCode)\n",
    "\n",
    "    indices = [\n",
    "        i\n",
    "        for i in range(len(labels))\n",
    "        if labels[i]\n",
    "        in [\n",
    "            b\"FDG\",\n",
    "            b\"AV45\",\n",
    "            b\"CDRSB\",\n",
    "            b\"ADAS13\",\n",
    "            b\"Ventricles\",\n",
    "            b\"Hippocampus\",\n",
    "            b\"WholeBrain\",\n",
    "            b\"Entorhinal\",\n",
    "            b\"MidTemp\",\n",
    "            b\"ABETA_UPENNBIOMK9_04_19_17\",\n",
    "            b\"TAU_UPENNBIOMK9_04_19_17\",\n",
    "            b\"PTAU_UPENNBIOMK9_04_19_17\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    print(\"labels\", labels[indices])\n",
    "    # print(adsa)\n",
    "    print(np.nanstd(data, axis=0)[indices])\n",
    "    data = params[\"data\"][:, indices]\n",
    "    params[\"data\"] = data\n",
    "    labels = labels[indices]\n",
    "    params[\"labels\"] = labels\n",
    "    nrBiomk = params[\"data\"].shape[1]\n",
    "    print(\"data.shape\", params[\"data\"].shape)\n",
    "    meanCTL = meanCTL[indices]\n",
    "    stdBiomkRescale = stdBiomkRescale[indices]\n",
    "    print(stdBiomkRescale)\n",
    "    print(\"flippedBiomk\", labels[stdBiomkRescale < 0])\n",
    "    sortedByPvalInd = np.argsort(np.argsort(sortedByPvalInd[indices]))\n",
    "\n",
    "    plotTrajParams[\"nearestNeighbours\"] = np.array(range(nrBiomk))\n",
    "    params[\"adjList\"] = np.nan\n",
    "    params[\"nearNeighInitClust\"] = np.array(range(nrBiomk))\n",
    "    params[\"initClustSubsetInd\"] = np.array(range(nrBiomk))\n",
    "    params[\"meanBiomkRescale\"] = meanCTL  # for rescaling back if necessary\n",
    "    params[\"stdBiomkRescale\"] = stdBiomkRescale\n",
    "\n",
    "    params[\n",
    "        \"fixSpeed\"\n",
    "    ] = False  # if true then don't model progression speed, only time shift\n",
    "\n",
    "    diagNrs = np.unique(diag)\n",
    "\n",
    "    sys.stdout.flush()\n",
    "    assert (\n",
    "        params[\"data\"].shape[0]\n",
    "        == params[\"diag\"].shape[0]\n",
    "        == params[\"scanTimepts\"].shape[0]\n",
    "        == params[\"partCode\"].shape[0]\n",
    "        == params[\"ageAtScan\"].shape[0]\n",
    "    )\n",
    "\n",
    "    # sets an uninformative or informative prior\n",
    "    priorNr = setPrior(\n",
    "        params,\n",
    "        args.informPrior,\n",
    "        mean_gamma_alpha=1,\n",
    "        std_gamma_alpha=0.1,\n",
    "        mu_beta=0,\n",
    "        std_beta=5,\n",
    "    )\n",
    "\n",
    "    suffix = \"\"\n",
    "    if args.leaderboard:\n",
    "        suffix = \"Ldb\"\n",
    "\n",
    "    expName = \"tadpoleInit%sCl%dPr%dRa%d%s\" % (\n",
    "        args.initClustering,\n",
    "        params[\"nrClust\"],\n",
    "        priorNr,\n",
    "        args.rangeFactor,\n",
    "        suffix,\n",
    "    )\n",
    "    plotTrajParams[\"sortedByPvalInd\"] = sortedByPvalInd\n",
    "    plotTrajParams[\"pointIndices\"] = pointIndices\n",
    "    plotTrajParams[\"expName\"] = expName\n",
    "    plotTrajParams[\"ageTransform\"] = (0, 1)  # no age normalisation was necessary\n",
    "    plotTrajParams[\"datasetFull\"] = params[\"datasetFull\"]\n",
    "    plotTrajParams[\"labels\"] = labels\n",
    "\n",
    "    params[\"plotTrajParams\"] = plotTrajParams\n",
    "\n",
    "    # R - run that checkpoint, L - load result from checkpoint\n",
    "    # [initClust, modelFit, AIC/BIC, blender, theta_sampling]\n",
    "    params[\"runPartStd\"] = [\"R\", \"R\", \"I\", \"I\", \"I\"]\n",
    "    params[\"runPartMain\"] = [\n",
    "        \"R\",\n",
    "        \"I\",\n",
    "        \"I\",\n",
    "        \"I\",\n",
    "    ]  # [mainPart, plot, stage, globalMinStats]\n",
    "    params[\"runPartCogCorr\"] = [\"I\"]\n",
    "    params[\"runPartCogCorrMain\"] = [\"L\", \"L\", \"I\", \"I\", \"L\"]\n",
    "    params[\"runPartDirDiag\"] = [\"R\", \"R\", \"I\"]\n",
    "    params[\"runPartStaging\"] = [\"L\", \"L\", \"I\"]\n",
    "    params[\"runPartDiffDiag\"] = [\"R\", \"R\", \"I\"]\n",
    "    params[\"runPartConvPred\"] = [\"I\", \"I\", \"I\"]\n",
    "    params[\"runPartCVNonOverlap\"] = [\"R\"]\n",
    "    params[\"runPartCVNonOverlapMain\"] = [\"L\", \"L\", \"I\", \"I\", \"L\"]\n",
    "    params[\"masterProcess\"] = runIndex == 0\n",
    "\n",
    "    if params[\"masterProcess\"]:\n",
    "        # [initClust, modelFit, AIC/BIC, blender, theta_sampling]\n",
    "        params[\"runPartStd\"] = [\"L\", \"L\", \"I\", \"I\", \"I\"]\n",
    "        params[\"runPartMain\"] = [\n",
    "            \"R\",\n",
    "            \"R\",\n",
    "            \"R\",\n",
    "            \"I\",\n",
    "        ]  # [mainPart, plot, stage, globalMinStats]\n",
    "        params[\"runPartCogCorr\"] = [\"I\"]\n",
    "        params[\"runPartCogCorrMain\"] = [\"L\", \"L\", \"I\", \"I\", \"I\"]\n",
    "        params[\"runPartDirDiag\"] = [\"R\", \"R\", \"I\"]\n",
    "        params[\"runPartStaging\"] = [\"L\", \"L\", \"I\"]\n",
    "        params[\"runPartDiffDiag\"] = [\"R\", \"R\", \"I\"]\n",
    "        params[\"runPartConvPred\"] = [\"I\", \"I\", \"I\"]\n",
    "        params[\"runPartCVNonOverlap\"] = [\"I\"]\n",
    "        params[\"runPartCVNonOverlapMain\"] = [\"R\", \"R\", \"I\", \"R\", \"R\"]\n",
    "\n",
    "    runAllExpFunc = runAllExpTADPOLE\n",
    "    modelNames, res = evaluationFramework.runModels(\n",
    "        params, expName, modelToRun, runAllExpFunc\n",
    "    )\n",
    "\n",
    "    # now generate forecast\n",
    "    # print('Generating forecast ... ')\n",
    "    teamName = \"DIVE6\"\n",
    "    if args.get(\"leaderboard\"):\n",
    "        outputFile = \"TADPOLE_Submission_Leaderboard_%s.csv\" % teamName\n",
    "        predStartDate = datetime.date(2010, 5, 1)\n",
    "        nrYearsToPred = 7\n",
    "        nrMonthsToPred = 12 * nrYearsToPred  # 5 years\n",
    "    else:\n",
    "        outputFile = \"TADPOLE_Submission_%s.csv\" % teamName\n",
    "        predStartDate = datetime.date(2018, 1, 1)\n",
    "        nrYearsToPred = 5\n",
    "        nrMonthsToPred = 12 * nrYearsToPred  # 7 years\n",
    "\n",
    "    resCurrModel = res[0][\"std\"]\n",
    "\n",
    "    predAdasAllSubj, predVentsAllSubj, predDiagAllSubj = makeTadpoleForecast(\n",
    "        predStartDate, nrYearsToPred, nrMonthsToPred, resCurrModel, params\n",
    "    )\n",
    "\n",
    "    # write forecast to file\n",
    "    writeTadpoleSubmission(\n",
    "        predAdasAllSubj,\n",
    "        predVentsAllSubj,\n",
    "        predDiagAllSubj,\n",
    "        outputFile,\n",
    "        nrMonthsToPred,\n",
    "        predStartDate,\n",
    "        params,\n",
    "    )\n",
    "    logger.info(\"End launchTadpole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTadpoleForecast(\n",
    "    predStartDate, nrYearsToPred, nrMonthsToPred, resCurrModel, params\n",
    "):\n",
    "\n",
    "    yearsFromPredStartToEachPredDate = np.linspace(\n",
    "        0, nrYearsToPred, num=nrMonthsToPred, endpoint=False\n",
    "    )\n",
    "\n",
    "    nrClust = params[\"nrClust\"]\n",
    "    assert abs(yearsFromPredStartToEachPredDate[1] - (1.0 / 12)) < 0.00001\n",
    "    # make predictions\n",
    "    startMonth = dateDiffToMonths(refDate - predStartDate)\n",
    "\n",
    "    trajFunc = sigmoidFunc\n",
    "\n",
    "    unqPartCodeFromRes = resCurrModel[\"uniquePartCode\"]\n",
    "    predInd = params[\"predInd\"]\n",
    "    predSetRidUnq = np.unique(predInd)\n",
    "\n",
    "    nrSubjPredSet = predSetRidUnq.shape[0]\n",
    "    # for each patient\n",
    "    clustProbBC = resCurrModel[\"clustProb\"]\n",
    "    thetas = resCurrModel[\"thetas\"]\n",
    "    variances = resCurrModel[\"variances\"]\n",
    "\n",
    "    labels = params[\"labels\"]\n",
    "    indexAdas = np.where(labels == b\"ADAS13\")[0][0]\n",
    "    indexVents = np.where(labels == b\"Ventricles\")[0][0]\n",
    "\n",
    "    predDiagAllSubj = np.zeros((nrSubjPredSet, nrMonthsToPred, 3), np.float)\n",
    "    predAdasAllSubj = np.zeros((nrSubjPredSet, nrMonthsToPred, 3), np.float)\n",
    "    predVentsAllSubj = np.zeros((nrSubjPredSet, nrMonthsToPred, 3), np.float)\n",
    "\n",
    "    dpsCross = resCurrModel[\"dpsCross\"]\n",
    "    crossDiag = resCurrModel[\"crossDiag\"]\n",
    "\n",
    "    dpsCTL = dpsCross[crossDiag == CTL]\n",
    "    dpsMCI = dpsCross[crossDiag == MCI]\n",
    "    dpsAD = dpsCross[crossDiag == AD]\n",
    "\n",
    "    partCode = params[\"partCode\"]\n",
    "    partCodeCurr = resCurrModel[\"crossPartCode\"]\n",
    "    # ageAtScan = resCurrModel['ageAtScan']\n",
    "\n",
    "    data = params[\"data\"]\n",
    "\n",
    "    # print(partCode.shape)\n",
    "    # print(partCodeCurr.shape)\n",
    "    assert partCodeCurr.shape[0] == partCode.shape[0]\n",
    "\n",
    "    kernelWidth = np.std(dpsCross) / 6  # need to test this parameter by visualisation\n",
    "\n",
    "    from sklearn.neighbors.kde import KernelDensity\n",
    "\n",
    "    kdeCTL = KernelDensity(kernel=\"gaussian\", bandwidth=kernelWidth).fit(\n",
    "        dpsCTL.reshape(-1, 1)\n",
    "    )\n",
    "    kdeMCI = KernelDensity(kernel=\"gaussian\", bandwidth=kernelWidth).fit(\n",
    "        dpsMCI.reshape(-1, 1)\n",
    "    )\n",
    "    kdeAD = KernelDensity(kernel=\"gaussian\", bandwidth=kernelWidth).fit(\n",
    "        dpsAD.reshape(-1, 1)\n",
    "    )\n",
    "\n",
    "    kdeXs = np.linspace(np.min(dpsCross), np.max(dpsCross), num=100).reshape(-1, 1)\n",
    "\n",
    "    fig = pl.figure(3)\n",
    "    pl.clf()\n",
    "    # print('kdeCTL.score_samples(kdeXs)', np.exp(kdeCTL.score_samples(kdeXs)))\n",
    "    pl.plot(\n",
    "        kdeXs,\n",
    "        np.exp(kdeCTL.score_samples(kdeXs)),\n",
    "        label=\"CTL\",\n",
    "        c=plotTrajParams[\"diagColors\"][CTL],\n",
    "    )\n",
    "    pl.plot(\n",
    "        kdeXs,\n",
    "        np.exp(kdeMCI.score_samples(kdeXs)),\n",
    "        label=\"MCI\",\n",
    "        c=plotTrajParams[\"diagColors\"][MCI],\n",
    "    )\n",
    "    pl.plot(\n",
    "        kdeXs,\n",
    "        np.exp(kdeAD.score_samples(kdeXs)),\n",
    "        label=\"AD\",\n",
    "        c=plotTrajParams[\"diagColors\"][AD],\n",
    "    )\n",
    "    pl.legend()\n",
    "    fig.show()\n",
    "    fig.savefig(\"%s/diagHist.png\" % (resCurrModel[\"outFolder\"]), dpi=100)\n",
    "\n",
    "    ageAtScan = params[\"ageAtScan\"]\n",
    "    examDates = params[\"examDates\"]\n",
    "\n",
    "    runPred = \"R\"\n",
    "    doPlot = 0\n",
    "    predFile = \"tadpolePredD2.npz\"\n",
    "\n",
    "    meanBiomkRescale = params[\"meanBiomkRescale\"]\n",
    "    stdBiomkRescale = params[\"stdBiomkRescale\"]\n",
    "\n",
    "    if runPred == \"R\":\n",
    "        for s in range(nrSubjPredSet):\n",
    "\n",
    "            ######### find dps at forecasted months ##########\n",
    "\n",
    "            # find age at forecasted months\n",
    "            subjRowsCurr = partCode == predSetRidUnq[s]\n",
    "\n",
    "            # import pdb\n",
    "            # pdb.set_trace()\n",
    "\n",
    "            # for one timepoint, find the age and the examDate\n",
    "            print(\"part : \", predSetRidUnq[s], np.sum(subjRowsCurr))\n",
    "            print(\"part ageAtScan: \", predSetRidUnq[s], ageAtScan[subjRowsCurr][0])\n",
    "\n",
    "            # compute age of subject at every prediction date\n",
    "            ageOneTimept = ageAtScan[subjRowsCurr][0]\n",
    "            examDateOneTimept = datetime.datetime.strptime(\n",
    "                examDates[subjRowsCurr][0], \"%Y-%m-%d\"\n",
    "            ).date()\n",
    "            yearsToPredStartDate = (predStartDate - examDateOneTimept).days / 365\n",
    "            ageAtPredDates = (\n",
    "                ageOneTimept + yearsToPredStartDate + yearsFromPredStartToEachPredDate\n",
    "            )\n",
    "\n",
    "            # compute dps\n",
    "            subShiftsCurr = resCurrModel[\"subShifts\"][\n",
    "                unqPartCodeFromRes == predSetRidUnq[s]\n",
    "            ]\n",
    "            dpsAtFutForecastDatesCurr = calcDpsGivenAges(ageAtPredDates, subShiftsCurr)\n",
    "\n",
    "            ######## find model predictions for those DPSs ##############3\n",
    "\n",
    "            futureForecastsAdas, futureForecastsVents = calcModelPredAdasVents(\n",
    "                dpsAtFutForecastDatesCurr,\n",
    "                thetas,\n",
    "                variances,\n",
    "                clustProbBC[indexAdas, :].T,\n",
    "                clustProbBC[indexVents, :].T,\n",
    "                trajFunc,\n",
    "            )\n",
    "\n",
    "            # add subject-specific intercept to the predictions, is subject has data\n",
    "            # warning: can contain NaNs and even be NaN in all entries.\n",
    "            adasDataCurrSubj = data[subjRowsCurr, indexAdas]\n",
    "            ventsDataCurrSubj = data[subjRowsCurr, indexVents]\n",
    "\n",
    "            ageCurrVisits = ageAtScan[subjRowsCurr]\n",
    "            dpsSubjCurrVisits = calcDpsGivenAges(ageCurrVisits, subShiftsCurr)\n",
    "            currVisitsPredAdas, currVisitsPredVents = calcModelPredAdasVents(\n",
    "                dpsSubjCurrVisits,\n",
    "                thetas,\n",
    "                variances,\n",
    "                clustProbBC[indexAdas, :].T,\n",
    "                clustProbBC[indexVents, :].T,\n",
    "                trajFunc,\n",
    "            )\n",
    "\n",
    "            futureForecastsAdas = addSubjIntercept(\n",
    "                dpsAtFutForecastDatesCurr,\n",
    "                futureForecastsAdas,\n",
    "                adasDataCurrSubj,\n",
    "                currVisitsPredAdas,\n",
    "            )\n",
    "            futureForecastsVents = addSubjIntercept(\n",
    "                dpsAtFutForecastDatesCurr,\n",
    "                futureForecastsVents,\n",
    "                ventsDataCurrSubj,\n",
    "                currVisitsPredVents,\n",
    "            )\n",
    "\n",
    "            # convert predictions back to un-normalised values\n",
    "\n",
    "            predAdasNotNorm = (\n",
    "                futureForecastsAdas * stdBiomkRescale[indexAdas]\n",
    "                + meanBiomkRescale[indexAdas]\n",
    "            )\n",
    "            predVentsNotNorm = (\n",
    "                futureForecastsVents * stdBiomkRescale[indexVents]\n",
    "                + meanBiomkRescale[indexVents]\n",
    "            )\n",
    "\n",
    "            predAdasAllSubj[s, :, :] = predAdasNotNorm\n",
    "            predAdasAllSubj[s, :, 1] = predAdasNotNorm[\n",
    "                :, 2\n",
    "            ]  # need invert lower& upper bounds due to sign change\n",
    "            predAdasAllSubj[s, :, 2] = predAdasNotNorm[:, 1]\n",
    "\n",
    "            predVentsAllSubj[s, :, :] = predVentsNotNorm\n",
    "            predVentsAllSubj[s, :, 1] = predVentsNotNorm[:, 2]\n",
    "            predVentsAllSubj[s, :, 2] = predVentsNotNorm[:, 1]\n",
    "\n",
    "            # print('predAdasNotNorm', predAdasNotNorm[0,:])\n",
    "            # print(adsa)\n",
    "\n",
    "            adasDataCurrSubjUnnorm = (\n",
    "                adasDataCurrSubj * stdBiomkRescale[indexAdas]\n",
    "                + meanBiomkRescale[indexAdas]\n",
    "            )\n",
    "            ventsDataCurrSubjUnnorm = (\n",
    "                ventsDataCurrSubj * stdBiomkRescale[indexVents]\n",
    "                + meanBiomkRescale[indexVents]\n",
    "            )\n",
    "\n",
    "            ctlLik = np.exp(\n",
    "                kdeCTL.score_samples(dpsAtFutForecastDatesCurr.reshape(-1, 1))\n",
    "            )\n",
    "            mciLik = np.exp(\n",
    "                kdeMCI.score_samples(dpsAtFutForecastDatesCurr.reshape(-1, 1))\n",
    "            )\n",
    "            adLik = np.exp(\n",
    "                kdeAD.score_samples(dpsAtFutForecastDatesCurr.reshape(-1, 1))\n",
    "            )\n",
    "\n",
    "            sumLik = ctlLik + mciLik + adLik\n",
    "\n",
    "            predDiagAllSubj[s, :, 0] = ctlLik / sumLik\n",
    "            predDiagAllSubj[s, :, 1] = mciLik / sumLik\n",
    "            predDiagAllSubj[s, :, 2] = adLik / sumLik\n",
    "\n",
    "            if doPlot:\n",
    "                if args.get(\"leaderboard\"):\n",
    "                    lb4Data = pd.read_csv(\"TADPOLE_LB4.csv\")\n",
    "                    lb4Data[\"CognitiveAssessmentDate\"] = [\n",
    "                        datetime.datetime.strptime(x, \"%Y-%m-%d\")\n",
    "                        for x in lb4Data[\"CognitiveAssessmentDate\"]\n",
    "                    ]\n",
    "                    lb4Data[\"ScanDate\"] = [\n",
    "                        datetime.datetime.strptime(x, \"%Y-%m-%d\").date()\n",
    "                        for x in lb4Data[\"ScanDate\"]\n",
    "                    ]\n",
    "                    mapping = {\"CN\": 0, \"MCI\": 1, \"AD\": 2}\n",
    "                    lb4Data.replace({\"Diagnosis\": mapping}, inplace=True)\n",
    "\n",
    "                    currSubjMaskLB4 = lb4Data.RID == predSetRidUnq[s]\n",
    "                    adasLB4CurrSubj = lb4Data.ADAS13[currSubjMaskLB4]\n",
    "                    ventsLB4CurrSubj = lb4Data.Ventricles[currSubjMaskLB4]\n",
    "                    diagLB4CurrSubj = lb4Data.Diagnosis[currSubjMaskLB4]\n",
    "\n",
    "                    datesLB4CurrSubj = lb4Data[\"CognitiveAssessmentDate\"][\n",
    "                        currSubjMaskLB4\n",
    "                    ]\n",
    "\n",
    "                    yearsFromRefDateToLB4Dates = np.array(\n",
    "                        [\n",
    "                            (d.date() - examDateOneTimept).days / 365\n",
    "                            for d in datesLB4CurrSubj\n",
    "                        ]\n",
    "                    )\n",
    "                    ageAtLB4datesCurrSubj = ageOneTimept + yearsFromRefDateToLB4Dates\n",
    "\n",
    "                    lb4Params = dict(\n",
    "                        adasLB4CurrSubj=adasLB4CurrSubj,\n",
    "                        ventsLB4CurrSubj=ventsLB4CurrSubj,\n",
    "                        diagLB4CurrSubj=diagLB4CurrSubj,\n",
    "                        ageAtLB4datesCurrSubj=ageAtLB4datesCurrSubj,\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                    lb4Params = None\n",
    "\n",
    "                plotSubjForecasts(\n",
    "                    predAdasAllSubj[s, :, :],\n",
    "                    predVentsAllSubj[s, :, :],\n",
    "                    predDiagAllSubj[s, :, :],\n",
    "                    ageAtPredDates,\n",
    "                    adasDataCurrSubjUnnorm,\n",
    "                    ventsDataCurrSubjUnnorm,\n",
    "                    ageCurrVisits,\n",
    "                    lb4Params,\n",
    "                    rid=predSetRidUnq[s],\n",
    "                )\n",
    "\n",
    "        ds = dict(\n",
    "            predAdasAllSubj=predAdasAllSubj,\n",
    "            predVentsAllSubj=predVentsAllSubj,\n",
    "            predDiagAllSubj=predDiagAllSubj,\n",
    "        )\n",
    "        pickle.dump(ds, open(predFile, \"wb\"), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    else:\n",
    "        ds = pickle.load(open(predFile, \"rb\"))\n",
    "        predAdasAllSubj = ds[\"predAdasAllSubj\"]\n",
    "        predVentsAllSubj = ds[\"predVentsAllSubj\"]\n",
    "        predDiagAllSubj = ds[\"predDiagAllSubj\"]\n",
    "\n",
    "    return predAdasAllSubj, predVentsAllSubj, predDiagAllSubj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSubjForecasts(\n",
    "    predAdasCurrSubj,\n",
    "    predVentsCurrSubj,\n",
    "    predDiagCurrSubj,\n",
    "    ageAtPredDates,\n",
    "    adasDataCurrSubjUnnorm,\n",
    "    ventsDataCurrSubjUnnorm,\n",
    "    ageCurrVisits,\n",
    "    lb4Params,\n",
    "    rid,\n",
    "):\n",
    "\n",
    "    if lb4Params is not None:\n",
    "        adasLB4CurrSubj = lb4Params[\"adasLB4CurrSubj\"]\n",
    "        ventsLB4CurrSubj = lb4Params[\"ventsLB4CurrSubj\"]\n",
    "        diagLB4CurrSubj = lb4Params[\"diagLB4CurrSubj\"]\n",
    "        ageAtLB4datesCurrSubj = lb4Params[\"ageAtLB4datesCurrSubj\"]\n",
    "\n",
    "    pl.figure(3)\n",
    "    ax = pl.subplot(1, 2, 1)\n",
    "    ax.set_title(\"ADAS RID:%d\" % rid)\n",
    "    pl.plot(ageAtPredDates, predAdasCurrSubj)\n",
    "    pl.scatter(ageCurrVisits, adasDataCurrSubjUnnorm, c=\"b\", s=10)\n",
    "    if lb4Params is not None:\n",
    "        pl.scatter(ageAtLB4datesCurrSubj, adasLB4CurrSubj, c=\"r\", s=10)\n",
    "\n",
    "    ax = pl.subplot(1, 2, 2)\n",
    "    ax.set_title(\"Vents RID:%d\" % rid)\n",
    "    pl.plot(ageAtPredDates, predVentsCurrSubj)\n",
    "    pl.scatter(ageCurrVisits, ventsDataCurrSubjUnnorm, c=\"b\", s=10)\n",
    "    if lb4Params is not None:\n",
    "        pl.scatter(ageAtLB4datesCurrSubj, ventsLB4CurrSubj, c=\"r\", s=10)\n",
    "\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcModelPredAdasVents(\n",
    "    dpsPredCurr, thetas, variances, clustProbAdas, clustProbVents, trajFunc\n",
    "):\n",
    "\n",
    "    nrClust = thetas.shape[0]\n",
    "    predCurrSubClustSC = np.zeros((dpsPredCurr.shape[0], nrClust), float)\n",
    "    predCurrSubClustSClower = np.zeros((dpsPredCurr.shape[0], nrClust), float)\n",
    "    predCurrSubClustSCupper = np.zeros((dpsPredCurr.shape[0], nrClust), float)\n",
    "\n",
    "    for c in range(nrClust):\n",
    "        predCurrSubClustSC[:, c] = trajFunc(dpsPredCurr, thetas[c, :])\n",
    "        predCurrSubClustSClower[:, c] = predCurrSubClustSC[:, c] - 0.33 * np.sqrt(\n",
    "            variances[c]\n",
    "        )\n",
    "        predCurrSubClustSCupper[:, c] = predCurrSubClustSC[:, c] + 0.33 * np.sqrt(\n",
    "            variances[c]\n",
    "        )\n",
    "\n",
    "    # from the predictions of each cluster trajectories, predict traj of ADAS and Vents\n",
    "    # using the probabilities of ADAS/Vents of being assigned to each cluster\n",
    "    futureForecastsAdas = np.zeros((predCurrSubClustSC.shape[0], 3))\n",
    "    futureForecastsVents = np.zeros((predCurrSubClustSC.shape[0], 3))\n",
    "\n",
    "    futureForecastsAdas[:, 0] = np.dot(predCurrSubClustSC, clustProbAdas)\n",
    "    futureForecastsVents[:, 0] = np.dot(predCurrSubClustSC, clustProbVents)\n",
    "\n",
    "    futureForecastsAdas[:, 1] = np.dot(predCurrSubClustSClower, clustProbAdas)\n",
    "    futureForecastsVents[:, 1] = np.dot(predCurrSubClustSClower, clustProbVents)\n",
    "\n",
    "    futureForecastsAdas[:, 2] = np.dot(predCurrSubClustSCupper, clustProbAdas)\n",
    "    futureForecastsVents[:, 2] = np.dot(predCurrSubClustSCupper, clustProbVents)\n",
    "\n",
    "    return futureForecastsAdas, futureForecastsVents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcDpsGivenAges(ageAtPredDates, subShiftsCurr):\n",
    "\n",
    "    subShiftsPredDates = np.tile(subShiftsCurr, (ageAtPredDates.shape[0], 1))\n",
    "\n",
    "    # print('subShiftsPredDates', subShiftsPredDates.shape)\n",
    "    # print('ageAtPredDates', ageAtPredDates.shape)\n",
    "    assert subShiftsPredDates.shape[0] == ageAtPredDates.shape[0]\n",
    "    assert subShiftsPredDates.shape[1] == 2\n",
    "\n",
    "    dpsPredCurr = VoxelDPM.calcDpsNo1array(subShiftsPredDates, ageAtPredDates)\n",
    "\n",
    "    return dpsPredCurr\n",
    "\n",
    "\n",
    "def addSubjIntercept(dpsT, futurePredictions, dataCurrSubjT, modelPredExistingVisits):\n",
    "\n",
    "    if np.isnan(dataCurrSubjT).all():\n",
    "        # no data available cur current subject, leave as population estimate\n",
    "        return futurePredictions\n",
    "    else:\n",
    "        # data is\n",
    "        return futurePredictions + (\n",
    "            np.nanmean(dataCurrSubjT) - np.mean(modelPredExistingVisits)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeTadpoleSubmission(\n",
    "    predAdasAllSubj,\n",
    "    predVentsAllSubj,\n",
    "    predDiagAllSubj,\n",
    "    outputFile,\n",
    "    nrMonthsToPred,\n",
    "    predStartDate,\n",
    "    params,\n",
    "):\n",
    "\n",
    "    predInd = params[\"predInd\"]\n",
    "    predSetRidUnq = np.unique(predInd)\n",
    "    # print('Writing forecast to file %s' % outputFile)\n",
    "    submission_table = pd.DataFrame()\n",
    "    nrSubjPredSet = predSetRidUnq.shape[0]\n",
    "    # * Repeated matrices - compare with submission template\n",
    "    submission_table[\"RID\"] = predSetRidUnq.repeat(nrMonthsToPred)\n",
    "    submission_table[\"Forecast Month\"] = np.tile(\n",
    "        range(1, nrMonthsToPred + 1), (nrSubjPredSet, 1)\n",
    "    ).flatten()\n",
    "\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "\n",
    "    endDate = predStartDate + relativedelta(months=+nrMonthsToPred - 1)\n",
    "    ForecastDates = [predStartDate]\n",
    "    while ForecastDates[-1] < endDate:\n",
    "        ForecastDates.append(ForecastDates[-1] + relativedelta(months=+1))\n",
    "\n",
    "    ForecastDatesStrings = [\n",
    "        datetime.datetime.strftime(d, \"%Y-%m\") for d in ForecastDates\n",
    "    ]\n",
    "    submission_table[\"Forecast Date\"] = np.tile(\n",
    "        ForecastDatesStrings, (nrSubjPredSet, 1)\n",
    "    ).flatten()\n",
    "    # * Pre-fill forecast data, encoding missing data as NaN\n",
    "    nanColumn = np.repeat(np.nan, submission_table.shape[0])\n",
    "    submission_table[\"CN relative probability\"] = nanColumn\n",
    "    submission_table[\"MCI relative probability\"] = nanColumn\n",
    "    submission_table[\"AD relative probability\"] = nanColumn\n",
    "    submission_table[\"ADAS13\"] = nanColumn\n",
    "    submission_table[\"ADAS13 50% CI lower\"] = nanColumn\n",
    "    submission_table[\"ADAS13 50% CI upper\"] = nanColumn\n",
    "    submission_table[\"Ventricles_ICV\"] = nanColumn\n",
    "    submission_table[\"Ventricles_ICV 50% CI lower\"] = nanColumn\n",
    "    submission_table[\"Ventricles_ICV 50% CI upper\"] = nanColumn\n",
    "\n",
    "    # *** Paste in month-by-month forecasts **\n",
    "    # * 1. Clinical status\n",
    "    submission_table[\"CN relative probability\"] = predDiagAllSubj[:, :, 0].flatten()\n",
    "    submission_table[\"MCI relative probability\"] = predDiagAllSubj[:, :, 1].flatten()\n",
    "    submission_table[\"AD relative probability\"] = predDiagAllSubj[:, :, 2].flatten()\n",
    "    # * 2. ADAS13 score\n",
    "    submission_table[\"ADAS13\"] = predAdasAllSubj[:, :, 0].flatten()\n",
    "    submission_table[\"ADAS13 50% CI lower\"] = predAdasAllSubj[:, :, 1].flatten()\n",
    "    submission_table[\"ADAS13 50% CI upper\"] = predAdasAllSubj[:, :, 2].flatten()\n",
    "    # * 3. Ventricles volume (normalised by intracranial volume)\n",
    "    submission_table[\"Ventricles_ICV\"] = predVentsAllSubj[:, :, 0].flatten()\n",
    "    submission_table[\"Ventricles_ICV 50% CI lower\"] = predVentsAllSubj[\n",
    "        :, :, 1\n",
    "    ].flatten()\n",
    "    submission_table[\"Ventricles_ICV 50% CI upper\"] = predVentsAllSubj[\n",
    "        :, :, 2\n",
    "    ].flatten()\n",
    "\n",
    "    submission_table.to_csv(outputFile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAllExpTADPOLE(params, expName, dpmBuilder):\n",
    "    \"\"\" runs all experiments\"\"\"\n",
    "\n",
    "    res = {}\n",
    "\n",
    "    params[\"patientID\"] = AD\n",
    "    params[\"excludeID\"] = -1\n",
    "    params[\"excludeXvalidID\"] = []\n",
    "    params[\"excludeStaging\"] = [-1]\n",
    "    params[\"anchorID\"] = MCI\n",
    "\n",
    "    # run if this is the master   process or nrProcesses is 1\n",
    "    unluckyProc = (\n",
    "        np.mod(params[\"currModel\"] - 1, params[\"nrProcesses\"]) == params[\"runIndex\"] - 1\n",
    "    )\n",
    "    unluckyOrNoParallel = (\n",
    "        unluckyProc or (params[\"nrProcesses\"] == 1) or params[\"masterProcess\"]\n",
    "    )\n",
    "\n",
    "    if unluckyOrNoParallel:\n",
    "        dpmObj, res[\"std\"] = evaluationFramework.runStdDPM(\n",
    "            params, expName, dpmBuilder, params[\"runPartMain\"]\n",
    "        )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResADNIthick(modelNames, res, plotTrajParams):\n",
    "    # nrModels = len(modelNames)\n",
    "\n",
    "    # dinamicModelName = 'VWDPMLinear'\n",
    "    # staticModelName = 'VWDPMLinearStatic'\n",
    "    # dinamicModelName = 'VDPM_MRF'\n",
    "    # staticModelName = 'VWDPMStatic'\n",
    "    # noDPSModelName = 'VDPMNoDPS'\n",
    "\n",
    "    print(\"##### biomk prediction ######\")\n",
    "    nrModels = len(modelNames)\n",
    "    pred = list(range(nrModels))\n",
    "    predMean = list(range(nrModels))\n",
    "    predStd = list(range(nrModels))\n",
    "    for m in range(nrModels):\n",
    "        pred[m] = res[m][\"cogCorr\"][\"predStats\"]\n",
    "        predMean[m] = np.nanmean(pred[m])\n",
    "        predStd[m] = np.nanstd(pred[m])\n",
    "\n",
    "    for m in range(nrModels):\n",
    "        print(\"%s predAllFolds\" % modelNames[m], pred[m])\n",
    "    for m in range(nrModels):\n",
    "        print(\"%s predMean\" % modelNames[m], predMean[m])\n",
    "    for m in range(nrModels):\n",
    "        print(\"%s predStd\" % modelNames[m], predStd[m])\n",
    "\n",
    "    stats = list(range(nrModels))\n",
    "    print(\"\\n##### correlation with cog tests ######\")\n",
    "    for m in range(nrModels):\n",
    "        stats[m] = res[m][\"cogCorr\"][\n",
    "            \"statsAllFolds\"\n",
    "        ]  # shape (NR_FOLDS, 2*NR_COG_TESTS)\n",
    "        # print('stats:', stats[m])\n",
    "        print(modelNames[m], end=\"\")\n",
    "        meanStats = np.nanmean(stats[m], 0)\n",
    "        stdStats = np.nanstd(stats[m], 0)\n",
    "        for i in range(meanStats.shape[0]):\n",
    "            print(\"%.2f +/- %.2f\" % (meanStats[i], stdStats[i]), end=\"\")\n",
    "        print(\"\")\n",
    "\n",
    "    plotScoresHist(scores=pred, labels=modelNames)\n",
    "\n",
    "    nrCogStats = stats[0].shape[1]\n",
    "\n",
    "    # perform paired t-test, as the same cross-validation folds have been used in both cases\n",
    "    tStats = np.zeros(nrCogStats, float)\n",
    "    pVals = np.zeros(nrCogStats, float)\n",
    "    for t in range(nrCogStats):\n",
    "        tStats[t], pVals[t] = scipy.stats.ttest_rel(stats[0][:, t], stats[0][:, t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
