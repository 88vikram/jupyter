{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMC-EB Example\n",
    "This python notebook trains, tests and evaluates the EMC-EB model. In the first piece of code, testing is done on a longitudinal data set (D2) and in the second piece of code, tesing is done on a cross-sectional data set (D3).\n",
    "Data set used for training and evalution D1 and D4 ADNI data sets respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model on data set D1 and test model on longitudinal data set D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Index(['RID', 'PTID', 'VISCODE', 'SITE', 'D1', 'D2', 'COLPROT', 'ORIGPROT',\n       'EXAMDATE', 'DX_bl',\n       ...\n       'PHASE_UPENNBIOMK9_04_19_17', 'BATCH_UPENNBIOMK9_04_19_17',\n       'KIT_UPENNBIOMK9_04_19_17', 'STDS_UPENNBIOMK9_04_19_17',\n       'RUNDATE_UPENNBIOMK9_04_19_17', 'ABETA_UPENNBIOMK9_04_19_17',\n       'TAU_UPENNBIOMK9_04_19_17', 'PTAU_UPENNBIOMK9_04_19_17',\n       'COMMENT_UPENNBIOMK9_04_19_17', 'update_stamp_UPENNBIOMK9_04_19_17'],\n      dtype='object', length=1907)\n100%|██████████| 1/1 [00:30<00:00, 30.97s/it]\n100%|██████████| 1/1 [00:00<00:00,  6.15it/s]\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from tadpole_algorithms.models import EMCEB\n",
    "from tadpole_algorithms.preprocessing.split import split_test_train_tadpole\n",
    "# Load D1_D2 evaluation data set\n",
    "data_path_train_test = Path(\"data/TADPOLE_D1_D2.csv\")\n",
    "data_df_train_test = pd.read_csv(data_path_train_test)\n",
    "\n",
    "# Load D4 evaluation data set\n",
    "data_path_eval = Path(\"data/TADPOLE_D4_corr.csv\")\n",
    "data_df_eval = pd.read_csv(data_path_eval)\n",
    "\n",
    "# Split data in test, train and evaluation data\n",
    "train_df, test_df, eval_df = split_test_train_tadpole(data_df_train_test, data_df_eval)\n",
    "\n",
    "# Indicate what data set is the training and testing dataset\n",
    "train = \"d1d2\"\n",
    "test = \"d1d2\"\n",
    "\n",
    "# Define model\n",
    "model = EMCEB()\n",
    "\n",
    "# Preprocess and set data \n",
    "model.set_data(train_df, test_df, train, test)\n",
    "\n",
    "# Train model\n",
    "# Note to self: number of bootstraps set to 1 for computation speed. Should be 100 to compute CIs.\n",
    "model.train()\n",
    "\n",
    "# Predict forecast on the test set\n",
    "forecast_df_d2 = model.predict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model on data set D1 and test model on cross sectional data set D3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1/1 [00:00<00:00,  2.01it/s]\n100%|██████████| 1/1 [00:00<00:00, 166.19it/s]\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from tadpole_algorithms.models import EMCEB\n",
    "from tadpole_algorithms.preprocessing.split import split_test_train_d3\n",
    "from tadpole_algorithms.preprocessing.rewrite_df import rewrite_d3\n",
    "\n",
    "# Load D1_D2 train and possible test data set\n",
    "data_path_train = Path(\"data/TADPOLE_D1_D2.csv\")\n",
    "data_df_train = pd.read_csv(data_path_train)\n",
    "\n",
    "# Load D3 possible test set\n",
    "data_path_test = Path(\"data/TADPOLE_D3.csv\")\n",
    "data_df_test = pd.read_csv(data_path_test)\n",
    "\n",
    "# Load D4 evaluation data set\n",
    "data_path_eval = Path(\"data/TADPOLE_D4_corr.csv\")\n",
    "data_df_eval = pd.read_csv(data_path_eval)\n",
    "\n",
    "# Split data in test, train and evulation data\n",
    "train_df, test_df, eval_df = split_test_train_d3(data_df_train, data_df_test, data_df_eval)\n",
    "test_df = rewrite_d3(test_df)\n",
    "\n",
    "# Indicate what data set is the training and testing dataset\n",
    "train = \"d1d2\"\n",
    "test = \"d3\"\n",
    "\n",
    "# Define model\n",
    "model = EMCEB()\n",
    "\n",
    "# Preprocess and set data \n",
    "model.set_data(train_df, test_df, train, test)\n",
    "\n",
    "# Train model\n",
    "# Note to self: number of bootstraps set to 1 for computation speed. Should be 100 to compute CIs.\n",
    "model.train()\n",
    "\n",
    "# Predict forecast on the test set\n",
    "forecast_df_d3 = model.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model tested on D2 on ADNI data set D4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[74 11  1]\n [22 70  0]\n [ 3 11 18]]\nmAUC (multiclass Area Under Curve):0.8741823884814031\nbca (balanced classification accuracy):0.9012726295255534\nadasMAE (ADAS13 Mean Aboslute Error):7.230222983080821\nventsMAE (Ventricles Mean Aboslute Error):0.018784692721531864\nadasWES (ADAS13 Weighted Error Score):nan\nventsWES (Ventricles Weighted Error Score ):nan\nadasCPA (ADAS13 Coverage Probability Accuracy for 50% Confidence Interval:0.5\nventsCPA (Ventricles Coverage Probability Accuracy for 50% Confidence Interval:0.5\n"
    }
   ],
   "source": [
    "from tadpole_algorithms.evaluation import evaluate_forecast\n",
    "from tadpole_algorithms.evaluation import print_metrics\n",
    "\n",
    "# Evaluate the model \n",
    "dictionary = evaluate_forecast(eval_df, forecast_df_d2)\n",
    "\n",
    "# Print metrics\n",
    "print_metrics(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model tested on D3 on ADNI data set D4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[74 10  2]\n [22 68  2]\n [ 3 12 17]]\nmAUC (multiclass Area Under Curve):0.8394711385916752\nbca (balanced classification accuracy):0.8738568083962822\nadasMAE (ADAS13 Mean Aboslute Error):6.369491636555709\nventsMAE (Ventricles Mean Aboslute Error):0.018784692721531864\nadasWES (ADAS13 Weighted Error Score):nan\nventsWES (Ventricles Weighted Error Score ):nan\nadasCPA (ADAS13 Coverage Probability Accuracy for 50% Confidence Interval:0.5\nventsCPA (Ventricles Coverage Probability Accuracy for 50% Confidence Interval:0.5\n"
    }
   ],
   "source": [
    "from tadpole_algorithms.evaluation import evaluate_forecast\n",
    "from tadpole_algorithms.evaluation import print_metrics\n",
    "\n",
    "# Evaluate the model \n",
    "dictionary = evaluate_forecast(eval_df, forecast_df_d3)\n",
    "\n",
    "# Print metrics\n",
    "print_metrics(dictionary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python_defaultSpec_1595323722228"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}