{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMC-EB Example\n",
    "This python notebook trains, tests and evaluates the EMC-EB model. In the first piece of code, testing is done on a longitudinal data set (D2) and in the second piece of code, tesing is done on a cross-sectional data set (D3).\n",
    "Data set used for training and evalution D1 and D4 ADNI data sets respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model on data set D1 and test model on longitudinal data set D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1/1 [00:29<00:00, 29.09s/it]\n100%|██████████| 1/1 [00:31<00:00, 31.26s/it]\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from tadpole_algorithms.models import EMCEB\n",
    "from tadpole_algorithms.preprocessing.split import split_test_train_tadpole\n",
    "# Load D1_D2 evaluation data set\n",
    "data_path_train_test = Path(\"data/TADPOLE_D1_D2.csv\")\n",
    "data_df_train_test = pd.read_csv(data_path_train_test)\n",
    "\n",
    "# Load D4 evaluation data set\n",
    "data_path_eval = Path(\"data/TADPOLE_D4_corr.csv\")\n",
    "data_df_eval = pd.read_csv(data_path_eval)\n",
    "\n",
    "# Split data in test, train and evaluation data\n",
    "train_df, test_df, eval_df = split_test_train_tadpole(data_df_train_test, data_df_eval)\n",
    "\n",
    "# Indicate what data set is the training and testing dataset\n",
    "train = \"d1d2\"\n",
    "test = \"d1d2\"\n",
    "\n",
    "# Define model\n",
    "model = EMCEB()\n",
    "\n",
    "# Preprocess and set data \n",
    "model.set_data(train_df, test_df, train, test)\n",
    "\n",
    "# Train model\n",
    "# Note to self: number of bootstraps set to 1 for computation speed. Should be 100 to compute CIs.\n",
    "model.train()\n",
    "\n",
    "# Predict forecast on the test set\n",
    "forecast_df_d2 = model.predict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model on data set D1 and test model on cross sectional data set D3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from tadpole_algorithms.models import EMCEB\n",
    "from tadpole_algorithms.preprocessing.split import split_test_train_d3\n",
    "from tadpole_algorithms.preprocessing.rewrite_df import rewrite_d3\n",
    "\n",
    "# Load D1_D2 train and possible test data set\n",
    "data_path_train = Path(\"data/TADPOLE_D1_D2.csv\")\n",
    "data_df_train = pd.read_csv(data_path_train)\n",
    "\n",
    "# Load D3 possible test set\n",
    "data_path_test = Path(\"data/TADPOLE_D3.csv\")\n",
    "data_df_test = pd.read_csv(data_path_test)\n",
    "\n",
    "# Load D4 evaluation data set\n",
    "data_path_eval = Path(\"data/TADPOLE_D4_corr.csv\")\n",
    "data_df_eval = pd.read_csv(data_path_eval)\n",
    "\n",
    "# Split data in test, train and evulation data\n",
    "train_df, test_df, eval_df = split_test_train_d3(data_df_train, data_df_test, data_df_eval)\n",
    "test_df = rewrite_d3(test_df)\n",
    "\n",
    "# Indicate what data set is the training and testing dataset\n",
    "train = \"d1d2\"\n",
    "test = \"d3\"\n",
    "\n",
    "# Define model\n",
    "model = EMCEB()\n",
    "\n",
    "# Preprocess and set data \n",
    "model.set_data(train_df, test_df, train, test)\n",
    "\n",
    "# Train model\n",
    "# Note to self: number of bootstraps set to 1 for computation speed. Should be 100 to compute CIs.\n",
    "model.train()\n",
    "\n",
    "# Predict forecast on the test set\n",
    "forecast_df_d3 = model.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model tested on D2 on ADNI data set D4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[75 11  0]\n [18 72  2]\n [ 2 15 15]]\nmAUC (multiclass Area Under Curve):0.8825280973084624\nbca (balanced classification accuracy):0.8929811024200491\nadasMAE (ADAS13 Mean Aboslute Error):6.782891500645058\nventsMAE (Ventricles Mean Aboslute Error):0.005580346787601667\nadasWES (ADAS13 Weighted Error Score):nan\nventsWES (Ventricles Weighted Error Score ):nan\nadasCPA (ADAS13 Coverage Probability Accuracy for 50% Confidence Interval:0.5\nventsCPA (Ventricles Coverage Probability Accuracy for 50% Confidence Interval:0.5\n"
    }
   ],
   "source": [
    "from tadpole_algorithms.evaluation import evaluate_forecast\n",
    "from tadpole_algorithms.evaluation import print_metrics\n",
    "\n",
    "# Evaluate the model \n",
    "dictionary = evaluate_forecast(eval_df, forecast_df_d2)\n",
    "\n",
    "# Print metrics\n",
    "print_metrics(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model tested on D3 on ADNI data set D4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[69 17  0]\n [16 74  2]\n [ 2 14 16]]\nmAUC (multiclass Area Under Curve):0.8745286452059269\nbca (balanced classification accuracy):0.8877634141304398\nadasMAE (ADAS13 Mean Aboslute Error):6.580346139857704\nventsMAE (Ventricles Mean Aboslute Error):0.008598618430909475\nadasWES (ADAS13 Weighted Error Score):nan\nventsWES (Ventricles Weighted Error Score ):nan\nadasCPA (ADAS13 Coverage Probability Accuracy for 50% Confidence Interval:0.5\nventsCPA (Ventricles Coverage Probability Accuracy for 50% Confidence Interval:0.5\n"
    }
   ],
   "source": [
    "from tadpole_algorithms.evaluation import evaluate_forecast\n",
    "from tadpole_algorithms.evaluation import print_metrics\n",
    "\n",
    "# Evaluate the model \n",
    "dictionary = evaluate_forecast(eval_df, forecast_df_d3)\n",
    "\n",
    "# Print metrics\n",
    "print_metrics(dictionary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python_defaultSpec_1598883460806"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}