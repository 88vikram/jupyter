{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMC-EB Example\n",
    "This python notebook trains, tests and evaluates the EMC-EB model. In the first piece of code, testing is done on a longitudinal data set (D2) and in the second piece of code, tesing is done on a cross-sectional data set (D3).\n",
    "Data set used for training and evalution D1 and D4 ADNI data sets respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model on data set D1 and test model on longitudinal data set D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Index(['RID', 'PTID', 'VISCODE', 'SITE', 'D1', 'D2', 'COLPROT', 'ORIGPROT',\n       'EXAMDATE', 'DX_bl',\n       ...\n       'PHASE_UPENNBIOMK9_04_19_17', 'BATCH_UPENNBIOMK9_04_19_17',\n       'KIT_UPENNBIOMK9_04_19_17', 'STDS_UPENNBIOMK9_04_19_17',\n       'RUNDATE_UPENNBIOMK9_04_19_17', 'ABETA_UPENNBIOMK9_04_19_17',\n       'TAU_UPENNBIOMK9_04_19_17', 'PTAU_UPENNBIOMK9_04_19_17',\n       'COMMENT_UPENNBIOMK9_04_19_17', 'update_stamp_UPENNBIOMK9_04_19_17'],\n      dtype='object', length=1907)\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from tadpole_algorithms.models import EMCEB\n",
    "from tadpole_algorithms.preprocessing.split import split_test_train_tadpole\n",
    "# Load D1_D2 evaluation data set\n",
    "data_path_train_test = Path(\"data/TADPOLE_D1_D2.csv\")\n",
    "data_df_train_test = pd.read_csv(data_path_train_test)\n",
    "\n",
    "# Load D4 evaluation data set\n",
    "data_path_eval = Path(\"data/TADPOLE_D4_corr.csv\")\n",
    "data_df_eval = pd.read_csv(data_path_eval)\n",
    "\n",
    "# Split data in test, train and evaluation data\n",
    "split_fraction = 0.1\n",
    "train_df, test_df, eval_df = split_test_train_tadpole(data_df_train_test, data_df_eval)\n",
    "test_df = test_df.fillna(0)\n",
    "\n",
    "# Indicate what data set is the training and testing dataset\n",
    "train = \"d1d2\"\n",
    "test = \"d1d2\"\n",
    "\n",
    "# Define model\n",
    "model = EMCEB()\n",
    "\n",
    "# Preprocess and set data \n",
    "model.set_data(train_df, test_df, train, test)\n",
    "print(test_df.columns)\n",
    "\n",
    "# Train model\n",
    "model.train()\n",
    "\n",
    "# Predict forecast on the test set\n",
    "forecast_df_d2 = model.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model on data set D1 and test model on cross sectional data set D3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1/1 [00:38<00:00, 38.14s/it]\n100%|██████████| 1/1 [00:00<00:00,  3.16it/s]\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from tadpole_algorithms.models import EMCEB\n",
    "from tadpole_algorithms.preprocessing.split import split_test_train_d3\n",
    "from tadpole_algorithms.preprocessing.rewrite_df import rewrite_d3\n",
    "\n",
    "# Load D1_D2 train and possible test data set\n",
    "data_path_train = Path(\"data/TADPOLE_D1_D2.csv\")\n",
    "data_df_train = pd.read_csv(data_path_train)\n",
    "\n",
    "# Load D3 possible test set\n",
    "data_path_test = Path(\"data/TADPOLE_D3.csv\")\n",
    "data_df_test = pd.read_csv(data_path_test)\n",
    "\n",
    "# Load D4 evaluation data set\n",
    "data_path_eval = Path(\"data/TADPOLE_D4_corr.csv\")\n",
    "data_df_eval = pd.read_csv(data_path_eval)\n",
    "\n",
    "# Split data in test, train and evulation data\n",
    "train_df, test_df, eval_df = split_test_train_d3(data_df_train, data_df_test, data_df_eval)\n",
    "test_df = test_df.fillna(0)\n",
    "test_df = rewrite_d3(test_df)\n",
    "\n",
    "# Indicate what data set is the training and testing dataset\n",
    "train = \"d1d2\"\n",
    "test = \"d3\"\n",
    "\n",
    "# Define model\n",
    "model = EMCEB()\n",
    "\n",
    "# Preprocess and set data \n",
    "model.set_data(train_df, test_df, train, test)\n",
    "\n",
    "# Train model\n",
    "model.train()\n",
    "\n",
    "# Predict forecast on the test set\n",
    "forecast_df_d3 = model.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model tested on D2 on ADNI data set D4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 0 86  0]\n [ 0 92  0]\n [ 0 32  0]]\nmAUC (multiclass Area Under Curve): 0.7872166519236041\nbca (balanced classification accuracy): 0.5431315694092063\nadasMAE (ADAS13 Mean Aboslute Error): 7.32568638224677\nventsMAE (Ventricles Mean Aboslute Error): 0.018784692721531868\nadasWES (ADAS13 Weighted Error Score): nan\nventsWES (Ventricles Weighted Error Score ): nan\nadasCPA (ADAS13 Coverage Probability Accuracy for 50% Confidence Interval: 0.5\nventsCPA (Ventricles Coverage Probability Accuracy for 50% Confidence Interval: 0.5\n"
    }
   ],
   "source": [
    "from tadpole_algorithms.evaluation import evaluate_forecast\n",
    "from tadpole_algorithms.evaluation import print_metrics\n",
    "\n",
    "# Evaluate the model \n",
    "dictionary = evaluate_forecast(eval_df, forecast_df_d2)\n",
    "\n",
    "# Print metrics\n",
    "print_metrics(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model tested on D3 on ADNI data set D4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 0 86  0]\n [ 0 92  0]\n [ 0 32  0]]\nmAUC (multiclass Area Under Curve): 0.539457454381286\nbca (balanced classification accuracy): 0.5431315694092063\nadasMAE (ADAS13 Mean Aboslute Error): 6.853459153810883\nventsMAE (Ventricles Mean Aboslute Error): 0.017984681227772418\nadasWES (ADAS13 Weighted Error Score): nan\nventsWES (Ventricles Weighted Error Score ): nan\nadasCPA (ADAS13 Coverage Probability Accuracy for 50% Confidence Interval: 0.5\nventsCPA (Ventricles Coverage Probability Accuracy for 50% Confidence Interval: 0.5\n"
    }
   ],
   "source": [
    "from tadpole_algorithms.evaluation import evaluate_forecast\n",
    "from tadpole_algorithms.evaluation import print_metrics\n",
    "\n",
    "# Evaluate the model \n",
    "dictionary = evaluate_forecast(eval_df, forecast_df_d3)\n",
    "\n",
    "# Print metrics\n",
    "print_metrics(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python37064bit608d3a8510c249f0a658c438feb769af"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}